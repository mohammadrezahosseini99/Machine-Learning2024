{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2e6Svw404_8w",
        "CrkWwZj2mpuk",
        "GM5dvlj-Wp2W",
        "qvRBubNtXO4Y",
        "46NIV5qyXP6H",
        "MFKSmw4K-AF4"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries and Dataset"
      ],
      "metadata": {
        "id": "2e6Svw404_8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import h5py\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import datetime\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from numba import njit\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.fftpack import fft"
      ],
      "metadata": {
        "id": "arfTwIzNuQjh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown 15anDcjyEVky89mIc_4Dskg7z2hQxVifN\n",
        "!gdown 1VL-87RmRuSOTFTFBO-CzXf404rOlnsH4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYnVZ9dNugnl",
        "outputId": "df9acd06-a970-415b-873a-46eee6e179d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.7.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 5.1.0\n",
            "    Uninstalling gdown-5.1.0:\n",
            "      Successfully uninstalled gdown-5.1.0\n",
            "Successfully installed gdown-5.2.0\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15anDcjyEVky89mIc_4Dskg7z2hQxVifN\n",
            "To: /content/sub_0.hdf\n",
            "100% 3.69M/3.69M [00:00<00:00, 49.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VL-87RmRuSOTFTFBO-CzXf404rOlnsH4\n",
            "To: /content/sub_1.hdf\n",
            "100% 3.69M/3.69M [00:00<00:00, 46.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r4X8uHffORp_"
      },
      "outputs": [],
      "source": [
        "class EEGDataset(Dataset):\n",
        "    # x_tensor: (sample, channel, datapoint(feature)) type = torch.tensor\n",
        "    # y_tensor: (sample,) type = torch.tensor\n",
        "\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "\n",
        "        self.x = x_tensor\n",
        "        self.y = y_tensor\n",
        "\n",
        "        assert self.x.size(0) == self.y.size(0)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing on the EEG data"
      ],
      "metadata": {
        "id": "CrkWwZj2mpuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Processer:\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.label = None\n",
        "        self.data_processed = None\n",
        "        self.label_processed = None\n",
        "    def load_data(self, path, subject):\n",
        "        path = Path(path)\n",
        "        data_list = []\n",
        "        label_list = []\n",
        "        for i in range(subject):\n",
        "            file_code = 'sub_'+ str(i)+'.hdf'\n",
        "            file = path / file_code\n",
        "            data_dictionary = h5py.File(file, 'r')\n",
        "            data = data_dictionary['data']\n",
        "            label = data_dictionary['label']\n",
        "            data_list.append(data)\n",
        "            label_list.append(label)\n",
        "            print('The shape of data is:'+ str(data_list[-1].shape))\n",
        "            print('The shape of label is:' + str(label_list[-1].shape))\n",
        "        self.data = np.stack(data_list, axis = 0)\n",
        "        self.label = np.stack(label_list, axis = 0)\n",
        "        # data: subject x trial x channels x datapoint\n",
        "        # label: subject x trial x datapoint\n",
        "        print('***************Data loaded successfully!***************')\n",
        "\n",
        "    def format_data(self):\n",
        "        # data: subject x trial x channels x datapoint\n",
        "        # label: subject x trial x datapoint\n",
        "        data = self.data\n",
        "        label = self.label\n",
        "\n",
        "        # change the label representation 1.0 -> 0.0; 2.0 -> 1.0\n",
        "        label[label == 1.0] = 0.0\n",
        "        label[label == 2.0] = 1.0\n",
        "\n",
        "        #Expand the frequency dimention\n",
        "        self.data_processed = np.expand_dims(data, axis = 2)\n",
        "\n",
        "        self.label_processed = label\n",
        "\n",
        "        print(\"The data shape is:\" + str(self.data_processed.shape))\n",
        "\n",
        "    def split_data(self, segment_length = 1, overlap = 0, sampling_rate = 256, save = True):\n",
        "        #data: subject x trial x 1 x channels x datapoint\n",
        "        #label: subject x trial x datapoint\n",
        "        #Parameters\n",
        "        data = self.data_processed\n",
        "        label = self.label_processed\n",
        "        #Split the data given\n",
        "        data_shape = data.shape\n",
        "        label_shape = label.shape\n",
        "        data_step = int(segment_length * sampling_rate * (1 - overlap))\n",
        "        data_segment = sampling_rate * segment_length\n",
        "        data_split = []\n",
        "        label_split = []\n",
        "\n",
        "        number_segment = int((label_shape[2]-data_segment)//(data_step)) + 1\n",
        "        for i in range(number_segment):\n",
        "            data_split.append(data[:,:,:,:,(i * data_step):(i * data_step + data_segment)])\n",
        "            label_split.append(label[:,:,(i * data_step)])\n",
        "        data_split_array = np.stack(data_split, axis = 2)\n",
        "        label_split_array = np.stack(label_split, axis = 2)\n",
        "        print(\"The data and label are splited: Data shape:\" + str(data_split_array.shape) +\" Label:\" + str(label_split_array.shape))\n",
        "        self.data_processed = data_split_array\n",
        "        self.label_processed = label_split_array\n",
        "\n",
        "\n",
        "        #TODO: Save the processed data here\n",
        "        if save == True:\n",
        "            if self.data_processed.all() != None:\n",
        "\n",
        "              save_path = Path(os.getcwd())\n",
        "              filename_data = save_path / Path('data_split.hdf')\n",
        "              save_data = h5py.File(filename_data, 'w')\n",
        "              save_data['data'] = self.data_processed\n",
        "              save_data['label'] = self.label_processed\n",
        "              save_data.close()\n",
        "              print(\"Data and Label saved successfully! at: \" + str(filename_data))\n",
        "            else :\n",
        "              print(\"data_splited is None\")"
      ],
      "metadata": {
        "id": "iHPy1k6WOinp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_path = os.getcwd()\n",
        "Pro = Processer()\n",
        "Pro.load_data(path=current_path,subject=2)\n",
        "Pro.format_data()\n",
        "Pro.split_data(segment_length = 4, overlap = 0.975, sampling_rate = 256, save = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w21wlDdXwMka",
        "outputId": "d1ad503e-2a05-48ab-9afb-159416442884"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of data is:(6, 4, 15360)\n",
            "The shape of label is:(6, 15360)\n",
            "The shape of data is:(6, 4, 15360)\n",
            "The shape of label is:(6, 15360)\n",
            "***************Data loaded successfully!***************\n",
            "The data shape is:(2, 6, 1, 4, 15360)\n",
            "The data and label are splited: Data shape:(2, 6, 574, 1, 4, 1024) Label:(2, 6, 574)\n",
            "Data and Label saved successfully! at: /content/data_split.hdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "YQs4BsSLm02m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################## TSception ######################################################\n",
        "class TSception(nn.Module):\n",
        "    def conv_block(self, in_chan, out_chan, kernel, step, pool):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_chan, out_channels=out_chan,\n",
        "                      kernel_size=kernel, stride=step, padding=0),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.AvgPool2d(kernel_size=(1, pool), stride=(1, pool)))\n",
        "\n",
        "    def __init__(self, num_classes, input_size, sampling_rate, num_T, num_S, hidden, dropout_rate):\n",
        "        # input_size: EEG channel x datapoint\n",
        "        super(TSception, self).__init__()\n",
        "        self.inception_window = [0.5, 0.25, 0.125]\n",
        "        self.pool = 8\n",
        "        # by setting the convolutional kernel being (1,lenght) and the strids being 1 we can use conv2d to\n",
        "        # achieve the 1d convolution operation\n",
        "        self.Tception1 = self.conv_block(1, num_T, (1, int(self.inception_window[0] * sampling_rate)), 1, self.pool)\n",
        "        self.Tception2 = self.conv_block(1, num_T, (1, int(self.inception_window[1] * sampling_rate)), 1, self.pool)\n",
        "        self.Tception3 = self.conv_block(1, num_T, (1, int(self.inception_window[2] * sampling_rate)), 1, self.pool)\n",
        "\n",
        "        self.Sception1 = self.conv_block(num_T, num_S, (int(input_size[-2]), 1), 1, int(self.pool*0.25))\n",
        "        self.Sception2 = self.conv_block(num_T, num_S, (int(input_size[-2] * 0.5), 1), (int(input_size[-2] * 0.5), 1),\n",
        "                                         int(self.pool*0.25))\n",
        "        self.BN_t = nn.BatchNorm2d(num_T)\n",
        "        self.BN_s = nn.BatchNorm2d(num_S)\n",
        "\n",
        "        size = self.get_size(input_size)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(size[1], hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.Tception1(x)\n",
        "        out = y\n",
        "        y = self.Tception2(x)\n",
        "        out = torch.cat((out, y), dim=-1)\n",
        "        y = self.Tception3(x)\n",
        "        out = torch.cat((out, y), dim=-1)\n",
        "        out = self.BN_t(out)\n",
        "        z = self.Sception1(out)\n",
        "        out_ = z\n",
        "        z = self.Sception2(out)\n",
        "        out_ = torch.cat((out_, z), dim=2)\n",
        "        out = self.BN_s(out_)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "    def get_size(self, input_size):\n",
        "        # here we use an array with the shape being\n",
        "        # (1(mini-batch),1(convolutional channel),EEG channel,time data point)\n",
        "        # to simulate the input data and get the output size\n",
        "        data = torch.ones((1, 1, input_size[-2], int(input_size[-1])))\n",
        "        y = self.Tception1(data)\n",
        "        out = y\n",
        "        y = self.Tception2(data)\n",
        "        out = torch.cat((out, y), dim=-1)\n",
        "        y = self.Tception3(data)\n",
        "        out = torch.cat((out, y), dim=-1)\n",
        "        out = self.BN_t(out)\n",
        "        z = self.Sception1(out)\n",
        "        out_final = z\n",
        "        z = self.Sception2(out)\n",
        "        out_final = torch.cat((out_final, z), dim=2)\n",
        "        out = self.BN_s(out_final)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return out.size()\n",
        "######################################### Temporal ########################################\n",
        "class Tception(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, sampling_rate, num_T, hidden, dropout_rate):\n",
        "        # input_size: channel x datapoint\n",
        "        super(Tception, self).__init__()\n",
        "        self.inception_window = [0.5, 0.25, 0.125, 0.0625, 0.03125]\n",
        "        # by setting the convolutional kernel being (1,lenght) and the strids being 1 we can use conv2d to\n",
        "        # achieve the 1d convolution operation\n",
        "        self.Tception1 = nn.Sequential(\n",
        "            nn.Conv2d(1, num_T, kernel_size=(1,int(self.inception_window[0]*sampling_rate)), stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=(1,16), stride=(1,16)))\n",
        "        self.Tception2 = nn.Sequential(\n",
        "            nn.Conv2d(1, num_T, kernel_size=(1,int(self.inception_window[1]*sampling_rate)), stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=(1,16), stride=(1,16)))\n",
        "        self.Tception3 = nn.Sequential(\n",
        "            nn.Conv2d(1, num_T, kernel_size=(1,int(self.inception_window[2]*sampling_rate)), stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=(1,16), stride=(1,16)))\n",
        "\n",
        "        self.BN_t = nn.BatchNorm2d(num_T)\n",
        "\n",
        "        size = self.get_size(input_size,sampling_rate,num_T)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(size[1], hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate))\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(hidden, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.Tception1(x)\n",
        "        out = y\n",
        "        y = self.Tception2(x)\n",
        "        out = torch.cat((out,y),dim = -1)\n",
        "        y = self.Tception3(x)\n",
        "        out = torch.cat((out,y),dim = -1)\n",
        "        out = self.BN_t(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    def get_size(self,input_size,sampling_rate,num_T):\n",
        "        data = torch.ones((1,1,input_size[0],input_size[1]))\n",
        "        y = self.Tception1(data)\n",
        "        out = y\n",
        "        y = self.Tception2(data)\n",
        "        out = torch.cat((out,y),dim = -1)\n",
        "        y = self.Tception3(data)\n",
        "        out = torch.cat((out,y),dim = -1)\n",
        "        out = self.BN_t(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return out.size()\n",
        "\n",
        "############################################ Spacial ########################################\n",
        "class Sception(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, sampling_rate, num_S, hidden, dropout_rate):\n",
        "        # input_size: channel x datapoint\n",
        "        super(Sception, self).__init__()\n",
        "\n",
        "        self.Sception1 = nn.Sequential(\n",
        "            nn.Conv2d(1, num_S, kernel_size=(int(input_size[0]),1), stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=(1,16), stride=(1,16)))\n",
        "        self.Sception2 = nn.Sequential(\n",
        "            nn.Conv2d(1, num_S, kernel_size=(int(input_size[0]*0.5),1), stride=(int(input_size[0]*0.5),1), padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=(1,16), stride=(1,16)))\n",
        "\n",
        "        self.BN_s = nn.BatchNorm2d(num_S)\n",
        "\n",
        "        size = self.get_size(input_size)\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(size[1], hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate))\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(hidden, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.Sception1(x)\n",
        "        out = y\n",
        "        y = self.Sception2(x)\n",
        "        out = torch.cat((out,y),dim = 2)\n",
        "        out = self.BN_s(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    def get_size(self, input_size):\n",
        "        data = torch.ones((1,1,input_size[0],input_size[1]))\n",
        "        y = self.Sception1(data)\n",
        "        out = y\n",
        "        y = self.Sception2(data)\n",
        "        out = torch.cat((out,y),dim = 2)\n",
        "        out = self.BN_s(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return out.size()"
      ],
      "metadata": {
        "id": "OeWzFX3bOT3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TSception(2,(4,1024),256,9,6,128,0.2)\n",
        "#model = Sception(2,(4,1024),256,6,128,0.2)\n",
        "#model = Tception(2,(4,1024),256,9,128,0.2)\n",
        "print(model)\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(pytorch_total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21LVHOkMwEw1",
        "outputId": "78f4339a-c4bf-49ad-9166-6bb4e9a503ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TSception(\n",
            "  (Tception1): Sequential(\n",
            "    (0): Conv2d(1, 9, kernel_size=(1, 128), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
            "  )\n",
            "  (Tception2): Sequential(\n",
            "    (0): Conv2d(1, 9, kernel_size=(1, 64), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
            "  )\n",
            "  (Tception3): Sequential(\n",
            "    (0): Conv2d(1, 9, kernel_size=(1, 32), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
            "  )\n",
            "  (Sception1): Sequential(\n",
            "    (0): Conv2d(9, 6, kernel_size=(4, 1), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)\n",
            "  )\n",
            "  (Sception2): Sequential(\n",
            "    (0): Conv2d(9, 6, kernel_size=(2, 1), stride=(2, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): AvgPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0)\n",
            "  )\n",
            "  (BN_t): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (BN_s): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3204, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "412907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainModel():\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.label = None\n",
        "        self.result = None\n",
        "        self.input_shape = None # should be (eeg_channel, time data point)\n",
        "        self.model = 'TSception'\n",
        "        self.cross_validation = 'Session' # Subject\n",
        "        self.sampling_rate = 256\n",
        "\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # Parameters: Training process\n",
        "        self.random_seed = 42\n",
        "        self.learning_rate = 1e-3\n",
        "        self.num_epochs = 200\n",
        "        self.num_class = 2\n",
        "        self.batch_size = 128\n",
        "        self.patient = 4\n",
        "\n",
        "        # Parameters: Model\n",
        "        self.dropout = 0.3\n",
        "        self.hidden_node = 128\n",
        "        self.T = 9\n",
        "        self.S = 6\n",
        "        self.Lambda = 1e-6\n",
        "\n",
        "    def load_data(self, path):\n",
        "        '''\n",
        "        This is the function to load the data\n",
        "        Data format : .hdf\n",
        "        Input : path\n",
        "                the path of your data\n",
        "                type = string\n",
        "        Data dimension : (subject x trials x segments x 1 x channel x data) type = numpy.array\n",
        "        Label dimension : (subject x trials x segments) type = numpy.array\n",
        "        Note : For different data formats, please change the loading\n",
        "               functions, (e.g. use h5py.File to load NAME.hdf)\n",
        "\n",
        "        '''\n",
        "        path = Path(path)\n",
        "        dataset = h5py.File(path, 'r')\n",
        "        self.data = np.array(dataset['data'])\n",
        "        self.label = np.array(dataset['label'])\n",
        "\n",
        "        # The input_shape should be (channel x data)\n",
        "        self.input_shape = self.data[0,0,0,0].shape\n",
        "\n",
        "        print('Data loaded!\\nData shape:[{}], Label shape:[{}]'\n",
        "              .format(self.data.shape,self.label.shape))\n",
        "\n",
        "    def set_parameter(self, cv, model, number_class, sampling_rate,\n",
        "                      random_seed, learning_rate, epoch, batch_size,\n",
        "                      dropout, hidden_node, patient,\n",
        "                      num_T, num_S, Lambda):\n",
        "        '''\n",
        "        This is the function to set the parameters of training process and model\n",
        "        All the settings will be saved into a NAME.txt file\n",
        "        Input : cv --\n",
        "                   The cross-validation type\n",
        "                   Type = string\n",
        "                   Default : Leave_one_session_out\n",
        "                   Note : for different cross validation type, please add the\n",
        "                          corresponding cross validation function. (e.g. self.Leave_one_session_out())\n",
        "\n",
        "                model --\n",
        "                   The model you want choose\n",
        "                   Type = string\n",
        "                   Default : TSception\n",
        "\n",
        "                number_class --\n",
        "                   The number of classes\n",
        "                   Type = int\n",
        "                   Default : 2\n",
        "\n",
        "                sampling_rate --\n",
        "                   The sampling rate of the EEG data\n",
        "                   Type = int\n",
        "                   Default : 256\n",
        "\n",
        "                random_seed --\n",
        "                   The random seed\n",
        "                   Type : int\n",
        "                   Default : 42\n",
        "\n",
        "                learning_rate --\n",
        "                   Learning rate\n",
        "                   Type : flaot\n",
        "                   Default : 0.001\n",
        "\n",
        "                epoch --\n",
        "                   Type : int\n",
        "                   Default : 200\n",
        "\n",
        "                batch_size --\n",
        "                   The size of mini-batch\n",
        "                   Type : int\n",
        "                   Default : 128\n",
        "\n",
        "                dropout --\n",
        "                   dropout rate of the fully connected layers\n",
        "                   Type : float\n",
        "                   Default : 0.3\n",
        "\n",
        "                hidden_node --\n",
        "                   The number of hidden node in the fully connected layer\n",
        "                   Type : int\n",
        "                   Default : 128\n",
        "\n",
        "                patient --\n",
        "                   How many epoches the training process should wait for\n",
        "                   It is used for the early-stopping\n",
        "                   Type : int\n",
        "                   Default : 4\n",
        "\n",
        "                num_T --\n",
        "                   The number of T kernels\n",
        "                   Type : int\n",
        "                   Default : 9\n",
        "\n",
        "                num_S --\n",
        "                   The number of S kernels\n",
        "                   Type : int\n",
        "                   Default : 6\n",
        "\n",
        "                Lambda --\n",
        "                   The L1 regulation coefficient in loss function\n",
        "                   Type : float\n",
        "                   Default : 1e-6\n",
        "\n",
        "        '''\n",
        "        self.model = model\n",
        "        self.sampling_rate = sampling_rate\n",
        "        # Parameters: Training process\n",
        "        self.random_seed = random_seed\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_epochs = epoch\n",
        "        self.num_class = number_class\n",
        "        self.batch_size = batch_size\n",
        "        self.patient = patient\n",
        "        self.Lambda = Lambda\n",
        "\n",
        "        # Parameters: Model\n",
        "        self.dropout = dropout\n",
        "        self.hidden_node = hidden_node\n",
        "        self.T = num_T\n",
        "        self.S = num_S\n",
        "\n",
        "\n",
        "        #Save to log file for checking\n",
        "        if cv == \"Leave_one_subject_out\":\n",
        "            file = open(\"result_subject.txt\",'a')\n",
        "        elif cv == \"Leave_one_session_out\":\n",
        "            file = open(\"result_session.txt\",'a')\n",
        "        elif cv == \"K_fold\":\n",
        "            file = open(\"result_k_fold.txt\",'a')\n",
        "        file.write(\"\\n\"+ str(datetime.datetime.now())+\n",
        "              \"\\nTrain:Parameter setting for \" + str(self.model) +\n",
        "              \"\\n1)number_class:\" + str(self.num_class) + \"\\n2)random_seed:\" + str(self.random_seed)+\n",
        "              \"\\n3)learning_rate:\" + str(self.learning_rate) + \"\\n4)num_epochs:\" + str(self.num_epochs) +\n",
        "              \"\\n5)batch_size:\" + str(self.batch_size)+\n",
        "              \"\\n6)dropout:\" + str(self.dropout) + \"\\n7)sampling_rate:\" + str(self.sampling_rate) +\n",
        "              \"\\n8)hidden_node:\" + str(self.hidden_node) + \"\\n9)input_shape:\" + str(self.input_shape) +\n",
        "              \"\\n10)patient:\" + str(self.patient) + \"\\n11)T:\" + str(self.T) +\n",
        "              \"\\n12)S:\" + str(self.S) + \"\\n13)Lambda:\" + str(self.Lambda) + '\\n')\n",
        "\n",
        "        file.close()\n",
        "\n",
        "    def Leave_one_session_out(self):\n",
        "        '''\n",
        "        This is the function to achieve 'Leave one session out' cross-validation\n",
        "        To know more details about 'Leave one session out', please refer to our paper\n",
        "\n",
        "        Note : all the acc and std will be logged into the result_session.txt\n",
        "\n",
        "               The txt file is located at the same location as the python script\n",
        "\n",
        "        '''\n",
        "        save_path = Path(os.getcwd())\n",
        "        if not os.path.exists(save_path / Path('Result_model/Leave_one_session_out/history')):\n",
        "            os.makedirs(save_path / Path('Result_model/Leave_one_session_out/history'))\n",
        "        #Data dimension: subject x trials x segments x 1 x channel x data\n",
        "        #Label dimension: subject x trials x segments\n",
        "        #Session: trials[0:2]-session 1; trials[2:4]-session 2; trials[4:end]-session 3\n",
        "        data = self.data\n",
        "        label = self.label\n",
        "        shape_data = data.shape\n",
        "        shape_label = label.shape\n",
        "        subject = shape_data[0]\n",
        "        trial = shape_data[1]\n",
        "        session = int(shape_data[1]/2)\n",
        "        channel = shape_data[4]\n",
        "        frequency = shape_data[3]\n",
        "        print(\"Train:Leave_one_session_out \\n1)shape of data:\" + str(shape_data) + \" \\n2)shape of label:\" + str(shape_label)+\n",
        "              \" \\n3)trials:\" + str(trial) + \" \\n4)session:\" + str(session) +\n",
        "              \" \\n5)datapoint:\" + str(frequency) + \" \\n6)channel:\" + str(channel))\n",
        "        #Train and evaluate the model subject by subject\n",
        "        ACC = []\n",
        "        ACC_mean = []\n",
        "        ACC_mean_val = []\n",
        "        for i in range(subject):\n",
        "            index = np.arange(trial)\n",
        "            ACC_subject = []\n",
        "            ACC_subject_val = []\n",
        "            for j in range(session):\n",
        "                # Split the data into training set and test set\n",
        "                # One session(contains 2 trials) is test set\n",
        "                # The rest are training set\n",
        "                index_train = np.delete(index,[2*j,2*j+1])\n",
        "                index_test = index[2*j:2*(j+1)]\n",
        "\n",
        "                data_train = data[i,index_train,:,:,:,:]\n",
        "                label_train = label[i,index_train,:]\n",
        "\n",
        "                data_test = data[i,index_test,:,:,:,:]\n",
        "                label_test = label[i,index_test,:]\n",
        "\n",
        "                # Split the training set into training set and validation set\n",
        "                data_train,label_train, data_val, label_val = self.split(data_train, label_train)\n",
        "\n",
        "                # Prepare the data format for training the model\n",
        "                data_train = torch.from_numpy(data_train).float()\n",
        "                label_train = torch.from_numpy(label_train).long()\n",
        "\n",
        "                data_val = torch.from_numpy(data_val).float()\n",
        "                label_val = torch.from_numpy(label_val).long()\n",
        "\n",
        "\n",
        "                data_test = torch.from_numpy(np.concatenate(data_test, axis = 0)).float()\n",
        "                label_test = torch.from_numpy(np.concatenate(label_test, axis = 0)).long()\n",
        "\n",
        "                # Check the dimension of the training, validation and test set\n",
        "                print('Training:', data_train.size(), label_train.size())\n",
        "                print('Validation:', data_val.size(), label_val.size())\n",
        "                print('Test:', data_test.size(), label_test.size())\n",
        "\n",
        "                # Get the accuracy of the model\n",
        "                ACC_session, acc_val = self.train(\n",
        "                    data_train,label_train,\n",
        "                    data_test,label_test,\n",
        "                    data_val, label_val,\n",
        "                    subject = i, session = j,\n",
        "                    cv_type = \"leave_one_session_out\")\n",
        "\n",
        "                ACC_subject.append(ACC_session)\n",
        "                ACC_subject_val.append(acc_val)\n",
        "                '''\n",
        "                # Log the results per session\n",
        "\n",
        "                file = open(\"result_session.txt\",'a')\n",
        "                file.write('Subject:'+str(i) +' Session:'+ str(j) + ' ACC:' + str(ACC_session) + '\\n')\n",
        "                file.close()\n",
        "                '''\n",
        "            ACC_subject = np.array(ACC_subject)\n",
        "            mAcc = np.mean(ACC_subject)\n",
        "            std = np.std(ACC_subject)\n",
        "\n",
        "            ACC_val = np.array(acc_val)\n",
        "            mAcc_val = np.mean(ACC_val)\n",
        "\n",
        "            print(\"Subject:\" + str(i) + \"\\nmACC: %.2f\" % mAcc)\n",
        "            print(\"std: %.2f\" % std)\n",
        "\n",
        "            # Log the results per subject\n",
        "            file = open(\"result_session.txt\",'a')\n",
        "            file.write('Subject:'+str(i) +' MeanACC:'+ str(mAcc) + ' Std:' + str(std) + '\\n')\n",
        "            file.close()\n",
        "\n",
        "            ACC.append(ACC_subject)\n",
        "            ACC_mean.append(mAcc)\n",
        "            ACC_mean_val.append(mAcc_val)\n",
        "\n",
        "        self.result = ACC\n",
        "        # Log the final Acc and std of all the subjects\n",
        "        file = open(\"result_session.txt\",'a')\n",
        "        file.write(\"\\n\"+ str(datetime.datetime.now()) +'\\nMeanACC:'+ str(np.mean(ACC_mean)) +\n",
        "                   ' Std:' + str(np.std(ACC_mean)) + ' Mean Val ACC:'+ str(np.mean(ACC_mean_val)) + '\\n')\n",
        "        file.close()\n",
        "        print(\"Mean ACC:\" + str(np.mean(ACC_mean)) + ' Std:' + str(np.std(ACC_mean)))\n",
        "\n",
        "        # Save the result\n",
        "        save_path = Path(os.getcwd())\n",
        "        filename_data = save_path / Path('Result_model/Result.hdf')\n",
        "        save_data = h5py.File(filename_data, 'w')\n",
        "        save_data['result'] = self.result\n",
        "        save_data.close()\n",
        "\n",
        "    def split(self, data, label):\n",
        "        '''\n",
        "        This is the function to split the training set into training set and validation set\n",
        "        Input : data --\n",
        "                The training data\n",
        "                Dimension : trials x segments x 1 x channel x data\n",
        "                Type : np.array\n",
        "\n",
        "                label --\n",
        "                The label of training data\n",
        "                Dimension : trials x segments\n",
        "                Type : np.array\n",
        "\n",
        "        Output : train --\n",
        "                 The split training data\n",
        "                 Dimension : trials x segments x 1 x channel x data\n",
        "                 Type : np.array\n",
        "\n",
        "                 train_label --\n",
        "                 The corresponding label of split training data\n",
        "                 Dimension : trials x segments\n",
        "                 Type : np.array\n",
        "\n",
        "                 val --\n",
        "                 The split validation data\n",
        "                 Dimension : trials x segments x 1 x channel x data\n",
        "                 Type : np.array\n",
        "\n",
        "                 val_label --\n",
        "                 The corresponding label of split validation data\n",
        "                 Dimension : trials x segments\n",
        "                 Type : np.array\n",
        "        '''\n",
        "        #Data dimension: trials x segments x 1 x channel x data\n",
        "        #Label dimension: trials x segments\n",
        "        np.random.seed(0)\n",
        "        data = np.concatenate(data, axis = 0)\n",
        "        label = np.concatenate(label, axis = 0)\n",
        "        #data : segments x 1 x channel x data\n",
        "        #label : segments\n",
        "        index = np.arange(data.shape[0])\n",
        "        index_randm = index\n",
        "        np.random.shuffle(index_randm)\n",
        "        label = label[index_randm]\n",
        "        data = data[index_randm]\n",
        "\n",
        "        # get validation set\n",
        "        val = data[int(data.shape[0]*0.8):]\n",
        "        val_label = label[int(data.shape[0]*0.8):]\n",
        "\n",
        "        train = data[0:int(data.shape[0]*0.8)]\n",
        "        train_label = label[0:int(data.shape[0]*0.8)]\n",
        "\n",
        "        return train, train_label, val, val_label\n",
        "\n",
        "    def make_train_step(self, model, loss_fn, optimizer):\n",
        "        def train_step(x,y):\n",
        "            model.train()\n",
        "            yhat = model(x)\n",
        "            pred = yhat.max(1)[1]\n",
        "            correct = (pred == y).sum()\n",
        "            acc = correct.item() / len(pred)\n",
        "            # L1 regularization\n",
        "            loss_r = self.regulization(model,self.Lambda)\n",
        "            # yhat is in one-hot representation;\n",
        "            loss = loss_fn(yhat, y) + loss_r\n",
        "            #loss = loss_fn(yhat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            return loss.item(), acc\n",
        "        return train_step\n",
        "\n",
        "    def regulization(self, model, Lambda):\n",
        "        w = torch.cat([x.view(-1) for x in model.parameters()])\n",
        "        err = Lambda * torch.sum(torch.abs(w))\n",
        "        return err\n",
        "\n",
        "    def train(self, train_data, train_label, test_data, test_label, val_data,\n",
        "              val_label, subject, session, cv_type):\n",
        "        # print('Avaliable device:' + str(torch.cuda.get_device_name(torch.cuda.current_device())))\n",
        "        torch.manual_seed(self.random_seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        # Train and validation loss\n",
        "        losses = []\n",
        "        accs = []\n",
        "\n",
        "        Acc_val = []\n",
        "        Loss_val = []\n",
        "        val_losses = []\n",
        "        val_acc = []\n",
        "\n",
        "        test_losses = []\n",
        "        test_acc = []\n",
        "        Acc_test = []\n",
        "\n",
        "        # hyper-parameter\n",
        "        learning_rate = self.learning_rate\n",
        "        num_epochs = self.num_epochs\n",
        "\n",
        "        # build the model\n",
        "        if self.model == 'Sception':\n",
        "            model = Sception(num_classes = self.num_class, input_size = self.input_shape,\n",
        "                             sampling_rate = self.sampling_rate, num_S = self.S,\n",
        "                             hidden = self.hidden_node, dropout_rate = self.dropout)\n",
        "        elif self.model == 'Tception':\n",
        "            model = Tception(num_classes = self.num_class, input_size = self.input_shape,\n",
        "                             sampling_rate = self.sampling_rate, num_T = self.T,\n",
        "                             hidden = self.hidden_node, dropout_rate = self.dropout)\n",
        "        elif self.model == 'TSception':\n",
        "            model = TSception(num_classes = self.num_class, input_size = self.input_shape,\n",
        "                              sampling_rate = self.sampling_rate, num_T = self.T, num_S = self.S,\n",
        "                              hidden = self.hidden_node, dropout_rate = self.dropout)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            model = model.to(self.device)\n",
        "            loss_fn = loss_fn.to(self.device)\n",
        "\n",
        "\n",
        "        train_step = self.make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "        # load the data\n",
        "        dataset_train = EEGDataset(train_data, train_label)\n",
        "        dataset_test = EEGDataset(test_data, test_label)\n",
        "        dataset_val = EEGDataset(val_data, val_label)\n",
        "\n",
        "        # Dataloader for training process\n",
        "        train_loader = DataLoader(dataset = dataset_train, batch_size = self.batch_size, shuffle = True,pin_memory = False)\n",
        "\n",
        "        val_loader = DataLoader(dataset = dataset_val, batch_size = self.batch_size, pin_memory = False)\n",
        "\n",
        "        test_loader = DataLoader(dataset = dataset_test, batch_size = self.batch_size, pin_memory = False)\n",
        "\n",
        "        total_step = len(train_loader)\n",
        "\n",
        "\n",
        "        ######## Training process ########\n",
        "        Acc = []\n",
        "        acc_max = 0\n",
        "        patient = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            loss_epoch = []\n",
        "            acc_epoch = []\n",
        "            for i, (x_batch,y_batch) in enumerate(train_loader):\n",
        "\n",
        "                x_batch = x_batch.to(self.device)\n",
        "                y_batch = y_batch.to(self.device)\n",
        "\n",
        "\n",
        "                loss, acc = train_step(x_batch,y_batch)\n",
        "                loss_epoch.append(loss)\n",
        "                acc_epoch.append(acc)\n",
        "\n",
        "            losses.append(sum(loss_epoch)/len(loss_epoch))\n",
        "            accs.append(sum(acc_epoch)/len(acc_epoch))\n",
        "            loss_epoch = []\n",
        "            acc_epoch = []\n",
        "            print ('Epoch [{}/{}], Loss: {:.4f}, Acc: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs,losses[-1] , accs[-1]))\n",
        "\n",
        "\n",
        "            ######## Validation process ########\n",
        "            with torch.no_grad():\n",
        "                for x_val, y_val in val_loader:\n",
        "                    x_val = x_val.to(self.device)\n",
        "                    y_val = y_val.to(self.device)\n",
        "\n",
        "                    model.eval()\n",
        "\n",
        "                    yhat = model(x_val)\n",
        "                    pred = yhat.max(1)[1]\n",
        "                    correct = (pred == y_val).sum()\n",
        "                    acc = correct.item() / len(pred)\n",
        "                    val_loss = loss_fn(yhat, y_val)\n",
        "                    val_losses.append(val_loss.item())\n",
        "                    val_acc.append(acc)\n",
        "\n",
        "                Acc_val.append(sum(val_acc)/len(val_acc))\n",
        "                Loss_val.append(sum(val_losses)/len(val_losses))\n",
        "                print('Evaluation Loss:{:.4f}, Acc: {:.4f}'\n",
        "                  .format(Loss_val[-1], Acc_val[-1]))\n",
        "                val_losses = []\n",
        "                val_acc = []\n",
        "\n",
        "            ######## early stop ########\n",
        "            Acc_es = Acc_val[-1]\n",
        "\n",
        "            if Acc_es > acc_max:\n",
        "                acc_max = Acc_es\n",
        "                patient = 0\n",
        "                print('----Model saved!----')\n",
        "                torch.save(model,'max_model.pt')\n",
        "            else :\n",
        "                patient += 1\n",
        "            if patient > self.patient:\n",
        "                print('----Early stopping----')\n",
        "                break\n",
        "\n",
        "\n",
        "        ######## test process ########\n",
        "        model = torch.load('max_model.pt')\n",
        "        with torch.no_grad():\n",
        "            for x_test, y_test in test_loader:\n",
        "\n",
        "                x_test = x_test.to(self.device)\n",
        "                y_test = y_test.to(self.device)\n",
        "\n",
        "                model.eval()\n",
        "\n",
        "                yhat = model(x_test)\n",
        "                pred = yhat.max(1)[1]\n",
        "                correct = (pred == y_test).sum()\n",
        "                acc = correct.item() / len(pred)\n",
        "                test_loss = loss_fn(yhat, y_test)\n",
        "                test_losses.append(test_loss.item())\n",
        "                test_acc.append(acc)\n",
        "\n",
        "            print('Test Loss:{:.4f}, Acc: {:.4f}'\n",
        "                  .format(sum(test_losses)/len(test_losses), sum(test_acc)/len(test_acc)))\n",
        "            Acc_test = (sum(test_acc)/len(test_acc))\n",
        "            test_losses = []\n",
        "            test_acc = []\n",
        "        # save the loss(acc) for plotting the loss(acc) curve\n",
        "        save_path = Path(os.getcwd())\n",
        "        if cv_type == \"leave_one_session_out\":\n",
        "            filename_callback = save_path / Path('Result_model/Leave_one_session_out/history/'\n",
        "                                                 + 'history_subject_' + str(subject) + '_session_'\n",
        "                                                 + str(session)+ '_history.hdf')\n",
        "            save_history = h5py.File(filename_callback, 'w')\n",
        "            save_history['acc'] = accs\n",
        "            save_history['val_acc'] = Acc_val\n",
        "            save_history['loss'] = losses\n",
        "            save_history['val_loss'] = Loss_val\n",
        "            save_history['max_acc'] = acc_max\n",
        "            save_history.close()\n",
        "        return Acc_test, acc_max"
      ],
      "metadata": {
        "id": "NJTTqjfuO4lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSception"
      ],
      "metadata": {
        "id": "GM5dvlj-Wp2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = TrainModel()\n",
        "train.load_data('data_split.hdf')\n",
        "train.set_parameter( cv = 'Leave_one_session_out',\n",
        "                      model = 'TSception',\n",
        "                      number_class = 2,\n",
        "                      sampling_rate = 256,\n",
        "                      random_seed = 42,\n",
        "                      learning_rate = 0.001,\n",
        "                      epoch = 200,\n",
        "                      batch_size = 128,\n",
        "                      dropout = 0.3,\n",
        "                      hidden_node = 128,\n",
        "                      patient = 4,\n",
        "                      num_T = 9,\n",
        "                      num_S = 6,\n",
        "                      Lambda = 0.000001)\n",
        "train.Leave_one_session_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhZiGLWvWoBo",
        "outputId": "a3326e4b-c85e-42e0-bb6c-43de2566971a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)session:3 \n",
            "5)datapoint:1 \n",
            "6)channel:4\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.4808, Acc: 0.7585\n",
            "Evaluation Loss:0.4677, Acc: 0.7440\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.0665, Acc: 0.9844\n",
            "Evaluation Loss:0.0740, Acc: 0.9738\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0106, Acc: 0.9995\n",
            "Evaluation Loss:0.0080, Acc: 1.0000\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0059, Acc: 1.0000\n",
            "Evaluation Loss:0.0023, Acc: 1.0000\n",
            "Epoch [5/200], Loss: 0.0051, Acc: 1.0000\n",
            "Evaluation Loss:0.0017, Acc: 1.0000\n",
            "Epoch [6/200], Loss: 0.0047, Acc: 1.0000\n",
            "Evaluation Loss:0.0012, Acc: 1.0000\n",
            "Epoch [7/200], Loss: 0.0047, Acc: 1.0000\n",
            "Evaluation Loss:0.0009, Acc: 1.0000\n",
            "Epoch [8/200], Loss: 0.0046, Acc: 1.0000\n",
            "Evaluation Loss:0.0008, Acc: 1.0000\n",
            "----Early stopping----\n",
            "Test Loss:0.6009, Acc: 0.8115\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.5721, Acc: 0.7049\n",
            "Evaluation Loss:0.5185, Acc: 0.7762\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.1149, Acc: 0.9771\n",
            "Evaluation Loss:0.0770, Acc: 0.9844\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0126, Acc: 0.9995\n",
            "Evaluation Loss:0.0140, Acc: 0.9948\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0058, Acc: 1.0000\n",
            "Evaluation Loss:0.0070, Acc: 0.9980\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0050, Acc: 1.0000\n",
            "Evaluation Loss:0.0045, Acc: 0.9980\n",
            "Epoch [6/200], Loss: 0.0048, Acc: 1.0000\n",
            "Evaluation Loss:0.0028, Acc: 0.9980\n",
            "Epoch [7/200], Loss: 0.0047, Acc: 1.0000\n",
            "Evaluation Loss:0.0013, Acc: 1.0000\n",
            "----Model saved!----\n",
            "Epoch [8/200], Loss: 0.0046, Acc: 1.0000\n",
            "Evaluation Loss:0.0011, Acc: 1.0000\n",
            "Epoch [9/200], Loss: 0.0046, Acc: 1.0000\n",
            "Evaluation Loss:0.0010, Acc: 1.0000\n",
            "Epoch [10/200], Loss: 0.0045, Acc: 1.0000\n",
            "Evaluation Loss:0.0009, Acc: 1.0000\n",
            "Epoch [11/200], Loss: 0.0045, Acc: 1.0000\n",
            "Evaluation Loss:0.0009, Acc: 1.0000\n",
            "Epoch [12/200], Loss: 0.0044, Acc: 1.0000\n",
            "Evaluation Loss:0.0008, Acc: 1.0000\n",
            "----Early stopping----\n",
            "Test Loss:0.0502, Acc: 0.9844\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.6437, Acc: 0.6282\n",
            "Evaluation Loss:0.6271, Acc: 0.6619\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.2281, Acc: 0.9490\n",
            "Evaluation Loss:0.1283, Acc: 0.9673\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0231, Acc: 0.9990\n",
            "Evaluation Loss:0.0167, Acc: 0.9967\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0072, Acc: 1.0000\n",
            "Evaluation Loss:0.0045, Acc: 1.0000\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0050, Acc: 1.0000\n",
            "Evaluation Loss:0.0033, Acc: 1.0000\n",
            "Epoch [6/200], Loss: 0.0050, Acc: 1.0000\n",
            "Evaluation Loss:0.0018, Acc: 1.0000\n",
            "Epoch [7/200], Loss: 0.0048, Acc: 1.0000\n",
            "Evaluation Loss:0.0016, Acc: 1.0000\n",
            "Epoch [8/200], Loss: 0.0046, Acc: 1.0000\n",
            "Evaluation Loss:0.0012, Acc: 1.0000\n",
            "Epoch [9/200], Loss: 0.0046, Acc: 1.0000\n",
            "Evaluation Loss:0.0011, Acc: 1.0000\n",
            "----Early stopping----\n",
            "Test Loss:0.0020, Acc: 1.0000\n",
            "Subject:0\n",
            "mACC: 0.93\n",
            "std: 0.09\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.5957, Acc: 0.6909\n",
            "Evaluation Loss:0.6739, Acc: 0.5393\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.1992, Acc: 0.9241\n",
            "Evaluation Loss:0.1803, Acc: 0.9243\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0857, Acc: 0.9682\n",
            "Evaluation Loss:0.1464, Acc: 0.9269\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0423, Acc: 0.9881\n",
            "Evaluation Loss:0.2106, Acc: 0.9086\n",
            "Epoch [5/200], Loss: 0.0282, Acc: 0.9938\n",
            "Evaluation Loss:0.0944, Acc: 0.9719\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.0117, Acc: 0.9995\n",
            "Evaluation Loss:0.0508, Acc: 0.9746\n",
            "----Model saved!----\n",
            "Epoch [7/200], Loss: 0.0109, Acc: 0.9995\n",
            "Evaluation Loss:0.0642, Acc: 0.9766\n",
            "----Model saved!----\n",
            "Epoch [8/200], Loss: 0.0082, Acc: 0.9995\n",
            "Evaluation Loss:0.0360, Acc: 0.9824\n",
            "----Model saved!----\n",
            "Epoch [9/200], Loss: 0.0061, Acc: 1.0000\n",
            "Evaluation Loss:0.0386, Acc: 0.9883\n",
            "----Model saved!----\n",
            "Epoch [10/200], Loss: 0.0056, Acc: 1.0000\n",
            "Evaluation Loss:0.0325, Acc: 0.9883\n",
            "Epoch [11/200], Loss: 0.0061, Acc: 1.0000\n",
            "Evaluation Loss:0.0536, Acc: 0.9824\n",
            "Epoch [12/200], Loss: 0.0068, Acc: 0.9995\n",
            "Evaluation Loss:0.0311, Acc: 0.9844\n",
            "Epoch [13/200], Loss: 0.0057, Acc: 1.0000\n",
            "Evaluation Loss:0.0323, Acc: 0.9863\n",
            "Epoch [14/200], Loss: 0.0051, Acc: 1.0000\n",
            "Evaluation Loss:0.0269, Acc: 0.9902\n",
            "----Model saved!----\n",
            "Epoch [15/200], Loss: 0.0049, Acc: 1.0000\n",
            "Evaluation Loss:0.0247, Acc: 0.9922\n",
            "----Model saved!----\n",
            "Epoch [16/200], Loss: 0.0047, Acc: 1.0000\n",
            "Evaluation Loss:0.0284, Acc: 0.9883\n",
            "Epoch [17/200], Loss: 0.0048, Acc: 1.0000\n",
            "Evaluation Loss:0.0217, Acc: 0.9883\n",
            "Epoch [18/200], Loss: 0.0047, Acc: 1.0000\n",
            "Evaluation Loss:0.0217, Acc: 0.9902\n",
            "Epoch [19/200], Loss: 0.0046, Acc: 1.0000\n",
            "Evaluation Loss:0.0217, Acc: 0.9922\n",
            "Epoch [20/200], Loss: 0.0049, Acc: 1.0000\n",
            "Evaluation Loss:0.0228, Acc: 0.9883\n",
            "----Early stopping----\n",
            "Test Loss:0.3887, Acc: 0.9670\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.5071, Acc: 0.7606\n",
            "Evaluation Loss:0.7705, Acc: 0.5497\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.1444, Acc: 0.9553\n",
            "Evaluation Loss:0.1805, Acc: 0.9394\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0576, Acc: 0.9812\n",
            "Evaluation Loss:0.1042, Acc: 0.9622\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0251, Acc: 0.9964\n",
            "Evaluation Loss:0.1099, Acc: 0.9661\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0158, Acc: 0.9969\n",
            "Evaluation Loss:0.0791, Acc: 0.9713\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.0105, Acc: 0.9995\n",
            "Evaluation Loss:0.0570, Acc: 0.9785\n",
            "----Model saved!----\n",
            "Epoch [7/200], Loss: 0.0093, Acc: 1.0000\n",
            "Evaluation Loss:0.0604, Acc: 0.9785\n",
            "Epoch [8/200], Loss: 0.0074, Acc: 1.0000\n",
            "Evaluation Loss:0.0667, Acc: 0.9824\n",
            "----Model saved!----\n",
            "Epoch [9/200], Loss: 0.0064, Acc: 0.9995\n",
            "Evaluation Loss:0.0446, Acc: 0.9824\n",
            "Epoch [10/200], Loss: 0.0053, Acc: 1.0000\n",
            "Evaluation Loss:0.0372, Acc: 0.9863\n",
            "----Model saved!----\n",
            "Epoch [11/200], Loss: 0.0059, Acc: 1.0000\n",
            "Evaluation Loss:0.0333, Acc: 0.9863\n",
            "Epoch [12/200], Loss: 0.0053, Acc: 1.0000\n",
            "Evaluation Loss:0.0430, Acc: 0.9883\n",
            "----Model saved!----\n",
            "Epoch [13/200], Loss: 0.0048, Acc: 1.0000\n",
            "Evaluation Loss:0.0411, Acc: 0.9922\n",
            "----Model saved!----\n",
            "Epoch [14/200], Loss: 0.0048, Acc: 1.0000\n",
            "Evaluation Loss:0.0374, Acc: 0.9941\n",
            "----Model saved!----\n",
            "Epoch [15/200], Loss: 0.0047, Acc: 1.0000\n",
            "Evaluation Loss:0.0345, Acc: 0.9922\n",
            "Epoch [16/200], Loss: 0.0046, Acc: 1.0000\n",
            "Evaluation Loss:0.0335, Acc: 0.9883\n",
            "Epoch [17/200], Loss: 0.0045, Acc: 1.0000\n",
            "Evaluation Loss:0.0371, Acc: 0.9941\n",
            "Epoch [18/200], Loss: 0.0047, Acc: 1.0000\n",
            "Evaluation Loss:0.0360, Acc: 0.9941\n",
            "Epoch [19/200], Loss: 0.0044, Acc: 1.0000\n",
            "Evaluation Loss:0.0300, Acc: 0.9922\n",
            "----Early stopping----\n",
            "Test Loss:0.3092, Acc: 0.9462\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.5048, Acc: 0.7517\n",
            "Evaluation Loss:0.7895, Acc: 0.5536\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.0941, Acc: 0.9641\n",
            "Evaluation Loss:0.0805, Acc: 0.9719\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0303, Acc: 0.9911\n",
            "Evaluation Loss:0.0204, Acc: 0.9928\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0180, Acc: 0.9948\n",
            "Evaluation Loss:0.0101, Acc: 0.9980\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0095, Acc: 0.9984\n",
            "Evaluation Loss:0.0074, Acc: 0.9980\n",
            "Epoch [6/200], Loss: 0.0069, Acc: 1.0000\n",
            "Evaluation Loss:0.0063, Acc: 0.9980\n",
            "Epoch [7/200], Loss: 0.0060, Acc: 1.0000\n",
            "Evaluation Loss:0.0081, Acc: 0.9980\n",
            "Epoch [8/200], Loss: 0.0052, Acc: 1.0000\n",
            "Evaluation Loss:0.0053, Acc: 0.9980\n",
            "Epoch [9/200], Loss: 0.0050, Acc: 1.0000\n",
            "Evaluation Loss:0.0054, Acc: 0.9980\n",
            "----Early stopping----\n",
            "Test Loss:0.5397, Acc: 0.8941\n",
            "Subject:1\n",
            "mACC: 0.94\n",
            "std: 0.03\n",
            "Mean ACC:0.9338551000597373 Std:0.0018994548984468396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sception"
      ],
      "metadata": {
        "id": "qvRBubNtXO4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = TrainModel()\n",
        "train.load_data('data_split.hdf')\n",
        "train.set_parameter( cv = 'Leave_one_session_out',\n",
        "                      model = 'Sception',\n",
        "                      number_class = 2,\n",
        "                      sampling_rate = 256,\n",
        "                      random_seed = 42,\n",
        "                      learning_rate = 0.001,\n",
        "                      epoch = 200,\n",
        "                      batch_size = 128,\n",
        "                      dropout = 0.3,\n",
        "                      hidden_node = 128,\n",
        "                      patient = 4,\n",
        "                      num_T = 9,\n",
        "                      num_S = 6,\n",
        "                      Lambda = 0.000001)\n",
        "train.Leave_one_session_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbtNV16kXPWj",
        "outputId": "e94cbd24-5199-46b3-a923-5d799903213c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)session:3 \n",
            "5)datapoint:1 \n",
            "6)channel:4\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.6454, Acc: 0.6223\n",
            "Evaluation Loss:0.6295, Acc: 0.6005\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.4201, Acc: 0.8643\n",
            "Evaluation Loss:0.4205, Acc: 0.8297\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.2483, Acc: 0.9282\n",
            "Evaluation Loss:0.2693, Acc: 0.9079\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.1547, Acc: 0.9636\n",
            "Evaluation Loss:0.2328, Acc: 0.9151\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.1055, Acc: 0.9693\n",
            "Evaluation Loss:0.1996, Acc: 0.9275\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.0820, Acc: 0.9802\n",
            "Evaluation Loss:0.2015, Acc: 0.9256\n",
            "Epoch [7/200], Loss: 0.0572, Acc: 0.9906\n",
            "Evaluation Loss:0.1783, Acc: 0.9230\n",
            "Epoch [8/200], Loss: 0.0419, Acc: 0.9943\n",
            "Evaluation Loss:0.1720, Acc: 0.9223\n",
            "Epoch [9/200], Loss: 0.0298, Acc: 0.9969\n",
            "Evaluation Loss:0.1562, Acc: 0.9262\n",
            "Epoch [10/200], Loss: 0.0358, Acc: 0.9954\n",
            "Evaluation Loss:0.1541, Acc: 0.9328\n",
            "----Model saved!----\n",
            "Epoch [11/200], Loss: 0.0206, Acc: 0.9984\n",
            "Evaluation Loss:0.1767, Acc: 0.9295\n",
            "Epoch [12/200], Loss: 0.0285, Acc: 0.9958\n",
            "Evaluation Loss:0.1619, Acc: 0.9445\n",
            "----Model saved!----\n",
            "Epoch [13/200], Loss: 0.0182, Acc: 0.9984\n",
            "Evaluation Loss:0.1477, Acc: 0.9419\n",
            "Epoch [14/200], Loss: 0.0173, Acc: 0.9979\n",
            "Evaluation Loss:0.1306, Acc: 0.9419\n",
            "Epoch [15/200], Loss: 0.0209, Acc: 0.9954\n",
            "Evaluation Loss:0.1282, Acc: 0.9394\n",
            "Epoch [16/200], Loss: 0.0175, Acc: 0.9974\n",
            "Evaluation Loss:0.1158, Acc: 0.9497\n",
            "----Model saved!----\n",
            "Epoch [17/200], Loss: 0.0144, Acc: 0.9995\n",
            "Evaluation Loss:0.1282, Acc: 0.9497\n",
            "Epoch [18/200], Loss: 0.0118, Acc: 0.9995\n",
            "Evaluation Loss:0.1165, Acc: 0.9478\n",
            "Epoch [19/200], Loss: 0.0137, Acc: 0.9979\n",
            "Evaluation Loss:0.1128, Acc: 0.9523\n",
            "----Model saved!----\n",
            "Epoch [20/200], Loss: 0.0098, Acc: 0.9995\n",
            "Evaluation Loss:0.1144, Acc: 0.9484\n",
            "Epoch [21/200], Loss: 0.0089, Acc: 0.9995\n",
            "Evaluation Loss:0.1229, Acc: 0.9445\n",
            "Epoch [22/200], Loss: 0.0128, Acc: 0.9979\n",
            "Evaluation Loss:0.1238, Acc: 0.9549\n",
            "----Model saved!----\n",
            "Epoch [23/200], Loss: 0.0117, Acc: 0.9980\n",
            "Evaluation Loss:0.1292, Acc: 0.9445\n",
            "Epoch [24/200], Loss: 0.0089, Acc: 0.9990\n",
            "Evaluation Loss:0.1148, Acc: 0.9458\n",
            "Epoch [25/200], Loss: 0.0089, Acc: 0.9995\n",
            "Evaluation Loss:0.1136, Acc: 0.9445\n",
            "Epoch [26/200], Loss: 0.0070, Acc: 1.0000\n",
            "Evaluation Loss:0.1201, Acc: 0.9497\n",
            "Epoch [27/200], Loss: 0.0092, Acc: 0.9990\n",
            "Evaluation Loss:0.1373, Acc: 0.9484\n",
            "----Early stopping----\n",
            "Test Loss:0.8114, Acc: 0.8148\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.6774, Acc: 0.5863\n",
            "Evaluation Loss:0.7118, Acc: 0.4999\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.4949, Acc: 0.8267\n",
            "Evaluation Loss:0.4755, Acc: 0.8824\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.3230, Acc: 0.9132\n",
            "Evaluation Loss:0.3685, Acc: 0.8962\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.2327, Acc: 0.9350\n",
            "Evaluation Loss:0.3402, Acc: 0.9001\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.1563, Acc: 0.9594\n",
            "Evaluation Loss:0.3281, Acc: 0.8948\n",
            "Epoch [6/200], Loss: 0.1217, Acc: 0.9677\n",
            "Evaluation Loss:0.3003, Acc: 0.9001\n",
            "Epoch [7/200], Loss: 0.0956, Acc: 0.9777\n",
            "Evaluation Loss:0.3260, Acc: 0.8968\n",
            "Epoch [8/200], Loss: 0.0715, Acc: 0.9834\n",
            "Evaluation Loss:0.2917, Acc: 0.9138\n",
            "----Model saved!----\n",
            "Epoch [9/200], Loss: 0.0554, Acc: 0.9912\n",
            "Evaluation Loss:0.3199, Acc: 0.8994\n",
            "Epoch [10/200], Loss: 0.0425, Acc: 0.9948\n",
            "Evaluation Loss:0.2983, Acc: 0.9059\n",
            "Epoch [11/200], Loss: 0.0403, Acc: 0.9917\n",
            "Evaluation Loss:0.3344, Acc: 0.9052\n",
            "Epoch [12/200], Loss: 0.0305, Acc: 0.9984\n",
            "Evaluation Loss:0.3469, Acc: 0.9079\n",
            "Epoch [13/200], Loss: 0.0321, Acc: 0.9958\n",
            "Evaluation Loss:0.2973, Acc: 0.9079\n",
            "----Early stopping----\n",
            "Test Loss:0.5260, Acc: 0.8428\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.6971, Acc: 0.5482\n",
            "Evaluation Loss:0.7277, Acc: 0.4704\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.5592, Acc: 0.7577\n",
            "Evaluation Loss:0.5795, Acc: 0.7230\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.4425, Acc: 0.8462\n",
            "Evaluation Loss:0.4851, Acc: 0.8111\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.3244, Acc: 0.8995\n",
            "Evaluation Loss:0.4128, Acc: 0.8256\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.2481, Acc: 0.9262\n",
            "Evaluation Loss:0.3952, Acc: 0.8358\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.1970, Acc: 0.9439\n",
            "Evaluation Loss:0.3493, Acc: 0.8595\n",
            "----Model saved!----\n",
            "Epoch [7/200], Loss: 0.1464, Acc: 0.9631\n",
            "Evaluation Loss:0.3369, Acc: 0.8771\n",
            "----Model saved!----\n",
            "Epoch [8/200], Loss: 0.1080, Acc: 0.9750\n",
            "Evaluation Loss:0.3412, Acc: 0.8418\n",
            "Epoch [9/200], Loss: 0.0849, Acc: 0.9849\n",
            "Evaluation Loss:0.3379, Acc: 0.8567\n",
            "Epoch [10/200], Loss: 0.0707, Acc: 0.9850\n",
            "Evaluation Loss:0.3435, Acc: 0.8699\n",
            "Epoch [11/200], Loss: 0.0599, Acc: 0.9917\n",
            "Evaluation Loss:0.3080, Acc: 0.8770\n",
            "Epoch [12/200], Loss: 0.0562, Acc: 0.9865\n",
            "Evaluation Loss:0.3345, Acc: 0.8627\n",
            "----Early stopping----\n",
            "Test Loss:0.1629, Acc: 0.9575\n",
            "Subject:0\n",
            "mACC: 0.87\n",
            "std: 0.06\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.6059, Acc: 0.6483\n",
            "Evaluation Loss:1.0356, Acc: 0.5262\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.4278, Acc: 0.8157\n",
            "Evaluation Loss:0.6175, Acc: 0.7010\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.3700, Acc: 0.8404\n",
            "Evaluation Loss:0.4254, Acc: 0.8108\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.3121, Acc: 0.8731\n",
            "Evaluation Loss:0.4263, Acc: 0.8035\n",
            "Epoch [5/200], Loss: 0.2667, Acc: 0.8899\n",
            "Evaluation Loss:0.4261, Acc: 0.8127\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.2279, Acc: 0.9155\n",
            "Evaluation Loss:0.4468, Acc: 0.8166\n",
            "----Model saved!----\n",
            "Epoch [7/200], Loss: 0.1869, Acc: 0.9382\n",
            "Evaluation Loss:0.4500, Acc: 0.8062\n",
            "Epoch [8/200], Loss: 0.1478, Acc: 0.9554\n",
            "Evaluation Loss:0.4612, Acc: 0.8029\n",
            "Epoch [9/200], Loss: 0.1123, Acc: 0.9679\n",
            "Evaluation Loss:0.5028, Acc: 0.8015\n",
            "Epoch [10/200], Loss: 0.0913, Acc: 0.9792\n",
            "Evaluation Loss:0.5004, Acc: 0.8121\n",
            "Epoch [11/200], Loss: 0.0850, Acc: 0.9777\n",
            "Evaluation Loss:0.5399, Acc: 0.7938\n",
            "----Early stopping----\n",
            "Test Loss:0.5840, Acc: 0.8498\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.5977, Acc: 0.6682\n",
            "Evaluation Loss:0.9862, Acc: 0.5262\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.4132, Acc: 0.8192\n",
            "Evaluation Loss:0.5863, Acc: 0.7251\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.3350, Acc: 0.8601\n",
            "Evaluation Loss:0.4468, Acc: 0.8036\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.2885, Acc: 0.8907\n",
            "Evaluation Loss:0.4447, Acc: 0.7983\n",
            "Epoch [5/200], Loss: 0.2565, Acc: 0.8970\n",
            "Evaluation Loss:0.4482, Acc: 0.7884\n",
            "Epoch [6/200], Loss: 0.2120, Acc: 0.9294\n",
            "Evaluation Loss:0.4796, Acc: 0.7911\n",
            "Epoch [7/200], Loss: 0.1804, Acc: 0.9413\n",
            "Evaluation Loss:0.5006, Acc: 0.7937\n",
            "Epoch [8/200], Loss: 0.1470, Acc: 0.9589\n",
            "Evaluation Loss:0.5055, Acc: 0.7911\n",
            "----Early stopping----\n",
            "Test Loss:0.4005, Acc: 0.8228\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.5986, Acc: 0.6816\n",
            "Evaluation Loss:1.0089, Acc: 0.5262\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.3616, Acc: 0.8648\n",
            "Evaluation Loss:0.6040, Acc: 0.7279\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.2944, Acc: 0.8835\n",
            "Evaluation Loss:0.3814, Acc: 0.8571\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.2442, Acc: 0.9105\n",
            "Evaluation Loss:0.3725, Acc: 0.8532\n",
            "Epoch [5/200], Loss: 0.2066, Acc: 0.9261\n",
            "Evaluation Loss:0.3627, Acc: 0.8669\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.1595, Acc: 0.9460\n",
            "Evaluation Loss:0.3840, Acc: 0.8655\n",
            "Epoch [7/200], Loss: 0.1282, Acc: 0.9605\n",
            "Evaluation Loss:0.4003, Acc: 0.8682\n",
            "----Model saved!----\n",
            "Epoch [8/200], Loss: 0.1034, Acc: 0.9714\n",
            "Evaluation Loss:0.3919, Acc: 0.8655\n",
            "Epoch [9/200], Loss: 0.0850, Acc: 0.9792\n",
            "Evaluation Loss:0.4100, Acc: 0.8564\n",
            "Epoch [10/200], Loss: 0.0647, Acc: 0.9881\n",
            "Evaluation Loss:0.4260, Acc: 0.8597\n",
            "Epoch [11/200], Loss: 0.0556, Acc: 0.9870\n",
            "Evaluation Loss:0.4475, Acc: 0.8519\n",
            "Epoch [12/200], Loss: 0.0455, Acc: 0.9906\n",
            "Evaluation Loss:0.4440, Acc: 0.8564\n",
            "----Early stopping----\n",
            "Test Loss:0.6013, Acc: 0.7792\n",
            "Subject:1\n",
            "mACC: 0.82\n",
            "std: 0.03\n",
            "Mean ACC:0.844496714456392 Std:0.027199074074074125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tception"
      ],
      "metadata": {
        "id": "46NIV5qyXP6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = TrainModel()\n",
        "train.load_data('data_split.hdf')\n",
        "train.set_parameter( cv = 'Leave_one_session_out',\n",
        "                      model = 'Tception',\n",
        "                      number_class = 2,\n",
        "                      sampling_rate = 256,\n",
        "                      random_seed = 42,\n",
        "                      learning_rate = 0.001,\n",
        "                      epoch = 200,\n",
        "                      batch_size = 128,\n",
        "                      dropout = 0.3,\n",
        "                      hidden_node = 128,\n",
        "                      patient = 4,\n",
        "                      num_T = 9,\n",
        "                      num_S = 6,\n",
        "                      Lambda = 0.000001)\n",
        "train.Leave_one_session_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGNhTFC4XQZM",
        "outputId": "8e767e3a-8250-4cf7-d52c-39baa1edaef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)session:3 \n",
            "5)datapoint:1 \n",
            "6)channel:4\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.4804, Acc: 0.7804\n",
            "Evaluation Loss:0.7985, Acc: 0.4463\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.0825, Acc: 0.9855\n",
            "Evaluation Loss:0.0745, Acc: 0.9719\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0173, Acc: 0.9969\n",
            "Evaluation Loss:0.0145, Acc: 0.9961\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0128, Acc: 0.9984\n",
            "Evaluation Loss:0.0259, Acc: 0.9902\n",
            "Epoch [5/200], Loss: 0.0092, Acc: 1.0000\n",
            "Evaluation Loss:0.0087, Acc: 0.9980\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.0081, Acc: 1.0000\n",
            "Evaluation Loss:0.0046, Acc: 1.0000\n",
            "----Model saved!----\n",
            "Epoch [7/200], Loss: 0.0074, Acc: 1.0000\n",
            "Evaluation Loss:0.0034, Acc: 1.0000\n",
            "Epoch [8/200], Loss: 0.0075, Acc: 1.0000\n",
            "Evaluation Loss:0.0030, Acc: 1.0000\n",
            "Epoch [9/200], Loss: 0.0074, Acc: 1.0000\n",
            "Evaluation Loss:0.0026, Acc: 1.0000\n",
            "Epoch [10/200], Loss: 0.0071, Acc: 1.0000\n",
            "Evaluation Loss:0.0023, Acc: 1.0000\n",
            "Epoch [11/200], Loss: 0.0070, Acc: 1.0000\n",
            "Evaluation Loss:0.0021, Acc: 1.0000\n",
            "----Early stopping----\n",
            "Test Loss:0.4337, Acc: 0.8835\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.5760, Acc: 0.7080\n",
            "Evaluation Loss:1.5553, Acc: 0.4463\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.1698, Acc: 0.9485\n",
            "Evaluation Loss:0.1842, Acc: 0.9412\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0354, Acc: 0.9958\n",
            "Evaluation Loss:0.1446, Acc: 0.9654\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0166, Acc: 0.9990\n",
            "Evaluation Loss:0.1252, Acc: 0.9693\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0106, Acc: 0.9995\n",
            "Evaluation Loss:0.0921, Acc: 0.9745\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.0086, Acc: 1.0000\n",
            "Evaluation Loss:0.0806, Acc: 0.9784\n",
            "----Model saved!----\n",
            "Epoch [7/200], Loss: 0.0081, Acc: 1.0000\n",
            "Evaluation Loss:0.0675, Acc: 0.9804\n",
            "----Model saved!----\n",
            "Epoch [8/200], Loss: 0.0077, Acc: 1.0000\n",
            "Evaluation Loss:0.0670, Acc: 0.9823\n",
            "----Model saved!----\n",
            "Epoch [9/200], Loss: 0.0080, Acc: 0.9995\n",
            "Evaluation Loss:0.0601, Acc: 0.9823\n",
            "Epoch [10/200], Loss: 0.0075, Acc: 1.0000\n",
            "Evaluation Loss:0.0581, Acc: 0.9823\n",
            "Epoch [11/200], Loss: 0.0074, Acc: 1.0000\n",
            "Evaluation Loss:0.0575, Acc: 0.9823\n",
            "Epoch [12/200], Loss: 0.0073, Acc: 1.0000\n",
            "Evaluation Loss:0.0610, Acc: 0.9823\n",
            "Epoch [13/200], Loss: 0.0072, Acc: 1.0000\n",
            "Evaluation Loss:0.0607, Acc: 0.9823\n",
            "----Early stopping----\n",
            "Test Loss:0.1019, Acc: 0.9582\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.6240, Acc: 0.6862\n",
            "Evaluation Loss:0.5545, Acc: 0.7395\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.1788, Acc: 0.9428\n",
            "Evaluation Loss:0.1850, Acc: 0.9274\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0413, Acc: 0.9891\n",
            "Evaluation Loss:0.1144, Acc: 0.9536\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0157, Acc: 0.9990\n",
            "Evaluation Loss:0.0575, Acc: 0.9751\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0096, Acc: 1.0000\n",
            "Evaluation Loss:0.0488, Acc: 0.9784\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.0084, Acc: 1.0000\n",
            "Evaluation Loss:0.0520, Acc: 0.9757\n",
            "Epoch [7/200], Loss: 0.0082, Acc: 1.0000\n",
            "Evaluation Loss:0.0528, Acc: 0.9751\n",
            "Epoch [8/200], Loss: 0.0081, Acc: 1.0000\n",
            "Evaluation Loss:0.0427, Acc: 0.9837\n",
            "----Model saved!----\n",
            "Epoch [9/200], Loss: 0.0078, Acc: 1.0000\n",
            "Evaluation Loss:0.0410, Acc: 0.9823\n",
            "Epoch [10/200], Loss: 0.0074, Acc: 1.0000\n",
            "Evaluation Loss:0.0432, Acc: 0.9757\n",
            "Epoch [11/200], Loss: 0.0074, Acc: 1.0000\n",
            "Evaluation Loss:0.0442, Acc: 0.9757\n",
            "Epoch [12/200], Loss: 0.0072, Acc: 1.0000\n",
            "Evaluation Loss:0.0468, Acc: 0.9757\n",
            "Epoch [13/200], Loss: 0.0071, Acc: 1.0000\n",
            "Evaluation Loss:0.0432, Acc: 0.9823\n",
            "----Early stopping----\n",
            "Test Loss:0.0125, Acc: 0.9965\n",
            "Subject:0\n",
            "mACC: 0.95\n",
            "std: 0.05\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.4924, Acc: 0.7539\n",
            "Evaluation Loss:1.5278, Acc: 0.5262\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.1876, Acc: 0.9314\n",
            "Evaluation Loss:0.2004, Acc: 0.9413\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.1268, Acc: 0.9569\n",
            "Evaluation Loss:0.1568, Acc: 0.9570\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0739, Acc: 0.9731\n",
            "Evaluation Loss:0.1600, Acc: 0.9668\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0566, Acc: 0.9824\n",
            "Evaluation Loss:0.1158, Acc: 0.9668\n",
            "Epoch [6/200], Loss: 0.0402, Acc: 0.9886\n",
            "Evaluation Loss:0.1170, Acc: 0.9570\n",
            "Epoch [7/200], Loss: 0.0602, Acc: 0.9786\n",
            "Evaluation Loss:0.1314, Acc: 0.9498\n",
            "Epoch [8/200], Loss: 0.0357, Acc: 0.9906\n",
            "Evaluation Loss:0.1083, Acc: 0.9648\n",
            "Epoch [9/200], Loss: 0.0188, Acc: 0.9969\n",
            "Evaluation Loss:0.1156, Acc: 0.9707\n",
            "----Model saved!----\n",
            "Epoch [10/200], Loss: 0.0267, Acc: 0.9908\n",
            "Evaluation Loss:0.1146, Acc: 0.9746\n",
            "----Model saved!----\n",
            "Epoch [11/200], Loss: 0.0825, Acc: 0.9670\n",
            "Evaluation Loss:0.1034, Acc: 0.9785\n",
            "----Model saved!----\n",
            "Epoch [12/200], Loss: 0.0559, Acc: 0.9803\n",
            "Evaluation Loss:0.1216, Acc: 0.9557\n",
            "Epoch [13/200], Loss: 0.0450, Acc: 0.9849\n",
            "Evaluation Loss:0.1107, Acc: 0.9629\n",
            "Epoch [14/200], Loss: 0.0184, Acc: 0.9953\n",
            "Evaluation Loss:0.1190, Acc: 0.9746\n",
            "Epoch [15/200], Loss: 0.0115, Acc: 0.9995\n",
            "Evaluation Loss:0.1139, Acc: 0.9648\n",
            "Epoch [16/200], Loss: 0.0096, Acc: 1.0000\n",
            "Evaluation Loss:0.1094, Acc: 0.9727\n",
            "----Early stopping----\n",
            "Test Loss:0.8874, Acc: 0.7734\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.5569, Acc: 0.7376\n",
            "Evaluation Loss:1.1500, Acc: 0.5379\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.2068, Acc: 0.9262\n",
            "Evaluation Loss:0.2309, Acc: 0.9400\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.1248, Acc: 0.9621\n",
            "Evaluation Loss:0.1625, Acc: 0.9576\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0754, Acc: 0.9803\n",
            "Evaluation Loss:0.1526, Acc: 0.9648\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0538, Acc: 0.9839\n",
            "Evaluation Loss:0.1406, Acc: 0.9688\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.0383, Acc: 0.9917\n",
            "Evaluation Loss:0.1461, Acc: 0.9688\n",
            "Epoch [7/200], Loss: 0.0381, Acc: 0.9901\n",
            "Evaluation Loss:0.1404, Acc: 0.9674\n",
            "Epoch [8/200], Loss: 0.0267, Acc: 0.9948\n",
            "Evaluation Loss:0.1412, Acc: 0.9655\n",
            "Epoch [9/200], Loss: 0.0253, Acc: 0.9932\n",
            "Evaluation Loss:0.1380, Acc: 0.9707\n",
            "----Model saved!----\n",
            "Epoch [10/200], Loss: 0.0175, Acc: 0.9974\n",
            "Evaluation Loss:0.1580, Acc: 0.9727\n",
            "----Model saved!----\n",
            "Epoch [11/200], Loss: 0.0292, Acc: 0.9902\n",
            "Evaluation Loss:0.1438, Acc: 0.9746\n",
            "----Model saved!----\n",
            "Epoch [12/200], Loss: 0.0184, Acc: 0.9969\n",
            "Evaluation Loss:0.1487, Acc: 0.9688\n",
            "Epoch [13/200], Loss: 0.0269, Acc: 0.9896\n",
            "Evaluation Loss:0.1337, Acc: 0.9674\n",
            "Epoch [14/200], Loss: 0.0156, Acc: 0.9969\n",
            "Evaluation Loss:0.1519, Acc: 0.9727\n",
            "Epoch [15/200], Loss: 0.0104, Acc: 1.0000\n",
            "Evaluation Loss:0.1399, Acc: 0.9746\n",
            "Epoch [16/200], Loss: 0.0084, Acc: 0.9995\n",
            "Evaluation Loss:0.1565, Acc: 0.9766\n",
            "----Model saved!----\n",
            "Epoch [17/200], Loss: 0.0078, Acc: 1.0000\n",
            "Evaluation Loss:0.1531, Acc: 0.9766\n",
            "Epoch [18/200], Loss: 0.0076, Acc: 1.0000\n",
            "Evaluation Loss:0.1571, Acc: 0.9766\n",
            "Epoch [19/200], Loss: 0.0076, Acc: 1.0000\n",
            "Evaluation Loss:0.1571, Acc: 0.9766\n",
            "Epoch [20/200], Loss: 0.0081, Acc: 1.0000\n",
            "Evaluation Loss:0.1549, Acc: 0.9785\n",
            "----Model saved!----\n",
            "Epoch [21/200], Loss: 0.0074, Acc: 0.9995\n",
            "Evaluation Loss:0.1521, Acc: 0.9746\n",
            "Epoch [22/200], Loss: 0.0069, Acc: 1.0000\n",
            "Evaluation Loss:0.1570, Acc: 0.9746\n",
            "Epoch [23/200], Loss: 0.0109, Acc: 0.9985\n",
            "Evaluation Loss:0.1628, Acc: 0.9766\n",
            "Epoch [24/200], Loss: 0.0104, Acc: 1.0000\n",
            "Evaluation Loss:0.1603, Acc: 0.9727\n",
            "Epoch [25/200], Loss: 0.0108, Acc: 0.9990\n",
            "Evaluation Loss:0.1715, Acc: 0.9688\n",
            "----Early stopping----\n",
            "Test Loss:0.3497, Acc: 0.9470\n",
            "Training: torch.Size([1836, 1, 4, 1024]) torch.Size([1836])\n",
            "Validation: torch.Size([460, 1, 4, 1024]) torch.Size([460])\n",
            "Test: torch.Size([1148, 1, 4, 1024]) torch.Size([1148])\n",
            "Epoch [1/200], Loss: 0.4959, Acc: 0.7694\n",
            "Evaluation Loss:1.6446, Acc: 0.5321\n",
            "----Model saved!----\n",
            "Epoch [2/200], Loss: 0.1403, Acc: 0.9553\n",
            "Evaluation Loss:0.1547, Acc: 0.9289\n",
            "----Model saved!----\n",
            "Epoch [3/200], Loss: 0.0734, Acc: 0.9757\n",
            "Evaluation Loss:0.0672, Acc: 0.9739\n",
            "----Model saved!----\n",
            "Epoch [4/200], Loss: 0.0621, Acc: 0.9782\n",
            "Evaluation Loss:0.0636, Acc: 0.9778\n",
            "----Model saved!----\n",
            "Epoch [5/200], Loss: 0.0275, Acc: 0.9932\n",
            "Evaluation Loss:0.0340, Acc: 0.9883\n",
            "----Model saved!----\n",
            "Epoch [6/200], Loss: 0.0205, Acc: 0.9943\n",
            "Evaluation Loss:0.0251, Acc: 0.9941\n",
            "----Model saved!----\n",
            "Epoch [7/200], Loss: 0.0155, Acc: 0.9979\n",
            "Evaluation Loss:0.0322, Acc: 0.9850\n",
            "Epoch [8/200], Loss: 0.0104, Acc: 1.0000\n",
            "Evaluation Loss:0.0258, Acc: 0.9889\n",
            "Epoch [9/200], Loss: 0.0108, Acc: 0.9984\n",
            "Evaluation Loss:0.0151, Acc: 0.9941\n",
            "Epoch [10/200], Loss: 0.0229, Acc: 0.9944\n",
            "Evaluation Loss:0.0335, Acc: 0.9869\n",
            "Epoch [11/200], Loss: 0.0201, Acc: 0.9953\n",
            "Evaluation Loss:0.0432, Acc: 0.9850\n",
            "----Early stopping----\n",
            "Test Loss:0.6926, Acc: 0.8889\n",
            "Subject:1\n",
            "mACC: 0.87\n",
            "std: 0.07\n",
            "Mean ACC:0.9079207735961767 Std:0.03813844086021506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "V1cUwgpUm5QX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature extraction and PCA"
      ],
      "metadata": {
        "id": "MFKSmw4K-AF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def fast_accuracy_score(y_true, y_pred):\n",
        "    correct = 0\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] == y_pred[i]:\n",
        "            correct += 1\n",
        "    return correct / len(y_true)\n",
        "\n",
        "def extract_features(signal):\n",
        "    features = []\n",
        "    for i in range(signal.shape[0]):\n",
        "        sig = signal[i]\n",
        "        mean = np.mean(sig)\n",
        "        var = np.var(sig)\n",
        "        max_val = np.max(sig)\n",
        "        min_val = np.min(sig)\n",
        "        range_val = max_val - min_val\n",
        "        std_dev = np.std(sig)\n",
        "        mean_power = np.mean(sig ** 2)\n",
        "        energy = np.sum(sig ** 2)\n",
        "        mean_abs = np.mean(np.abs(sig))\n",
        "        freq_domain = np.abs(fft(sig))\n",
        "        dom_freq = np.argmax(freq_domain)\n",
        "        features.extend([mean, var, max_val, min_val, range_val, std_dev, mean_power, energy, mean_abs, dom_freq])\n",
        "    return features\n",
        "\n",
        "class TrainModel():\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.label = None\n",
        "        self.result = None\n",
        "        self.input_shape = None\n",
        "        self.cross_validation = 'Session' # Subject\n",
        "        self.sampling_rate = 256\n",
        "\n",
        "        # Parameters: Training process\n",
        "        self.random_seed = 42\n",
        "        self.num_class = 2\n",
        "        self.test_size = 0.2\n",
        "\n",
        "        # Parameters: Model\n",
        "        self.kernel = 'rbf'\n",
        "        self.C = 1.0\n",
        "        self.gamma = 'scale'\n",
        "\n",
        "    def load_data(self, path):\n",
        "        path = Path(path)\n",
        "        dataset = h5py.File(path, 'r')\n",
        "        self.data = np.array(dataset['data'])\n",
        "        self.label = np.array(dataset['label'])\n",
        "\n",
        "        print('Data loaded!\\nData shape:[{}], Label shape:[{}]'\n",
        "              .format(self.data.shape, self.label.shape))\n",
        "\n",
        "    def set_parameter(self, cv, kernel, C, gamma, test_size):\n",
        "        self.kernel = kernel\n",
        "        self.C = C\n",
        "        self.gamma = gamma\n",
        "        self.test_size = test_size\n",
        "\n",
        "        # Save to log file for checking\n",
        "        if cv == \"Leave_one_subject_out\":\n",
        "            file = open(\"result_subject.txt\",'a')\n",
        "        elif cv == \"Leave_one_session_out\":\n",
        "            file = open(\"result_session.txt\",'a')\n",
        "        elif cv == \"K_fold\":\n",
        "            file = open(\"result_k_fold.txt\",'a')\n",
        "        file.write(\"\\n\"+ str(datetime.datetime.now())+\n",
        "              \"\\nTrain:Parameter setting for SVM\" +\n",
        "              \"\\n1)kernel:\" + str(self.kernel) + \"\\n2)C:\" + str(self.C) +\n",
        "              \"\\n3)gamma:\" + str(self.gamma) + \"\\n4)test_size:\" + str(self.test_size) + '\\n')\n",
        "\n",
        "        file.close()\n",
        "\n",
        "    def Leave_one_session_out(self):\n",
        "        save_path = Path(os.getcwd())\n",
        "        if not os.path.exists(save_path / Path('Result_model/Leave_one_session_out/history')):\n",
        "            os.makedirs(save_path / Path('Result_model/Leave_one_session_out/history'))\n",
        "\n",
        "        data = self.data\n",
        "        label = self.label\n",
        "        shape_data = data.shape\n",
        "        shape_label = label.shape\n",
        "        subject = shape_data[0]\n",
        "        trial = shape_data[1]\n",
        "        session = int(shape_data[1]/2)\n",
        "        channel = shape_data[4]\n",
        "        frequency = shape_data[5]\n",
        "        print(\"Train:Leave_one_session_out \\n1)shape of data:\" + str(shape_data) + \" \\n2)shape of label:\" + str(shape_label)+\n",
        "              \" \\n3)trials:\" + str(trial) + \" \\n4)sessions:\" + str(session) +\n",
        "              \" \\n5)datapoint:\" + str(frequency) + \" \\n6)channel:\" + str(channel))\n",
        "\n",
        "        ACC = []\n",
        "        ACC_mean = []\n",
        "        ACC_mean_val = []\n",
        "        for i in range(subject):\n",
        "            index = np.arange(trial)\n",
        "            ACC_subject = []\n",
        "            ACC_subject_val = []\n",
        "            for j in range(session):\n",
        "                index_train = np.delete(index, [2*j, 2*j+1])\n",
        "                index_test = index[2*j:2*(j+1)]\n",
        "\n",
        "                data_train = np.array([extract_features(data[i, idx, 0, 0, :, :]) for idx in index_train])\n",
        "                label_train = label[i, index_train, 0]  # Adjust label dimension\n",
        "\n",
        "                data_test = np.array([extract_features(data[i, idx, 0, 0, :, :]) for idx in index_test])\n",
        "                label_test = label[i, index_test, 0]  # Adjust label dimension\n",
        "\n",
        "                data_train, data_val, label_train, label_val = train_test_split(\n",
        "                    data_train, label_train, test_size=self.test_size, random_state=self.random_seed)\n",
        "\n",
        "                scaler = StandardScaler()\n",
        "                data_train = scaler.fit_transform(data_train)\n",
        "                data_val = scaler.transform(data_val)\n",
        "                data_test = scaler.transform(data_test)\n",
        "\n",
        "                # # Print the number of features before applying PCA\n",
        "                # print(f'Number of features before PCA: {data_train.shape[1]}')\n",
        "\n",
        "                # Applying PCA\n",
        "                pca = PCA(n_components=0.99)  # Keep 99% of variance\n",
        "                data_train = pca.fit_transform(data_train)\n",
        "                data_val = pca.transform(data_val)\n",
        "                data_test = pca.transform(data_test)\n",
        "\n",
        "                # # Print the number of features after applying PCA\n",
        "                # print(f'Number of features after PCA: {data_train.shape[1]}')\n",
        "\n",
        "                model = SVC(kernel=self.kernel, C=self.C, gamma=self.gamma, random_state=self.random_seed)\n",
        "                model.fit(data_train, label_train)\n",
        "\n",
        "                acc_train = fast_accuracy_score(label_train, model.predict(data_train))\n",
        "                acc_val = fast_accuracy_score(label_val, model.predict(data_val))\n",
        "                acc_test = fast_accuracy_score(label_test, model.predict(data_test))\n",
        "\n",
        "                ACC_subject.append(acc_test)\n",
        "                ACC_subject_val.append(acc_val)\n",
        "\n",
        "                print(f'Subject:{i}, Session:{j}, Train ACC:{acc_train:.4f}, Val ACC:{acc_val:.4f}, Test ACC:{acc_test:.4f}')\n",
        "\n",
        "            ACC_subject = np.array(ACC_subject)\n",
        "            mAcc = np.mean(ACC_subject)\n",
        "            std = np.std(ACC_subject)\n",
        "\n",
        "            ACC_val = np.array(ACC_subject_val)\n",
        "            mAcc_val = np.mean(ACC_val)\n",
        "\n",
        "            print(\"Subject:\" + str(i) + \"\\nmACC: %.2f\" % mAcc)\n",
        "            print(\"std: %.2f\" % std)\n",
        "\n",
        "            file = open(\"result_session.txt\", 'a')\n",
        "            file.write('Subject:' + str(i) + ' MeanACC:' + str(mAcc) + ' Std:' + str(std) + '\\n')\n",
        "            file.close()\n",
        "\n",
        "            ACC.append(ACC_subject)\n",
        "            ACC_mean.append(mAcc)\n",
        "            ACC_mean_val.append(mAcc_val)\n",
        "\n",
        "        self.result = ACC\n",
        "        file = open(\"result_session.txt\", 'a')\n",
        "        file.write(\"\\n\" + str(datetime.datetime.now()) +'\\nMeanACC:'+ str(np.mean(ACC_mean)) +\n",
        "                   ' Std:' + str(np.std(ACC_mean)) + ' Mean Val ACC:'+ str(np.mean(ACC_mean_val)) + '\\n')\n",
        "        file.close()\n",
        "        print(\"Mean ACC:\" + str(np.mean(ACC_mean)) + ' Std:' + str(np.std(ACC_mean)))\n",
        "\n",
        "        save_path = Path(os.getcwd())\n",
        "        filename_data = save_path / Path('Result_model/Result.hdf')\n",
        "        save_data = h5py.File(filename_data, 'w')\n",
        "        save_data['result'] = self.result\n",
        "        save_data.close()\n",
        "        return np.mean(ACC_mean)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f'Model with parameters: (kernel=\\'rbf\\', C=1.0, gamma=\\'scale\\') is starting...')\n",
        "    train = TrainModel()\n",
        "    train.load_data('data_split.hdf')\n",
        "    train.set_parameter(cv='Leave_one_session_out', kernel='rbf', C=1.0, gamma='scale', test_size=0.2)\n",
        "    train.Leave_one_session_out()\n"
      ],
      "metadata": {
        "id": "kG9IknWPxPjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c9aacf-b2e2-40a9-a29d-56e23abf4405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with parameters: (kernel='rbf', C=1.0, gamma='scale') is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:1.0000, Val ACC:1.0000, Test ACC:0.5000\n",
            "Subject:0, Session:1, Train ACC:1.0000, Val ACC:0.0000, Test ACC:0.5000\n",
            "Subject:0, Session:2, Train ACC:0.6667, Val ACC:0.0000, Test ACC:0.5000\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.0000, Test ACC:0.5000\n",
            "Subject:1, Session:1, Train ACC:0.6667, Val ACC:0.0000, Test ACC:0.5000\n",
            "Subject:1, Session:2, Train ACC:0.6667, Val ACC:0.0000, Test ACC:0.5000\n",
            "Subject:1\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Mean ACC:0.5 Std:0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without feature extraction"
      ],
      "metadata": {
        "id": "7Bm8Z0-f-Dvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Whithout PCA"
      ],
      "metadata": {
        "id": "meLirt2wVlj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def fast_accuracy_score(y_true, y_pred):\n",
        "    correct = 0\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] == y_pred[i]:\n",
        "            correct += 1\n",
        "    return correct / len(y_true)\n",
        "\n",
        "class TrainModel():\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.label = None\n",
        "        self.result = None\n",
        "        self.input_shape = None\n",
        "        self.cross_validation = 'Session' # Subject\n",
        "        self.sampling_rate = 256\n",
        "\n",
        "        # Parameters: Training process\n",
        "        self.random_seed = 42\n",
        "        self.num_class = 2\n",
        "        self.test_size = 0.2\n",
        "\n",
        "        # Parameters: Model\n",
        "        self.kernel = 'rbf'\n",
        "        self.C = 1.0\n",
        "        self.gamma = 'scale'\n",
        "\n",
        "    def load_data(self, path):\n",
        "        path = Path(path)\n",
        "        dataset = h5py.File(path, 'r')\n",
        "        self.data = np.array(dataset['data'])\n",
        "        self.label = np.array(dataset['label'])\n",
        "\n",
        "        # The input_shape should be (channel x data)\n",
        "        self.input_shape = self.data[0,0,0,0].shape\n",
        "\n",
        "        print('Data loaded!\\nData shape:[{}], Label shape:[{}]'\n",
        "              .format(self.data.shape,self.label.shape))\n",
        "\n",
        "    def set_parameter(self, cv, kernel, C, gamma, test_size):\n",
        "        self.kernel = kernel\n",
        "        self.C = C\n",
        "        self.gamma = gamma\n",
        "        self.test_size = test_size\n",
        "\n",
        "        # Save to log file for checking\n",
        "        if cv == \"Leave_one_subject_out\":\n",
        "            file = open(\"result_subject.txt\",'a')\n",
        "        elif cv == \"Leave_one_session_out\":\n",
        "            file = open(\"result_session.txt\",'a')\n",
        "        elif cv == \"K_fold\":\n",
        "            file = open(\"result_k_fold.txt\",'a')\n",
        "        file.write(\"\\n\"+ str(datetime.datetime.now())+\n",
        "              \"\\nTrain:Parameter setting for SVM\" +\n",
        "              \"\\n1)kernel:\" + str(self.kernel) + \"\\n2)C:\" + str(self.C) +\n",
        "              \"\\n3)gamma:\" + str(self.gamma) + \"\\n4)test_size:\" + str(self.test_size) + '\\n')\n",
        "\n",
        "        file.close()\n",
        "\n",
        "    def Leave_one_session_out(self):\n",
        "        save_path = Path(os.getcwd())\n",
        "        if not os.path.exists(save_path / Path('Result_model/Leave_one_session_out/history')):\n",
        "            os.makedirs(save_path / Path('Result_model/Leave_one_session_out/history'))\n",
        "\n",
        "        data = self.data\n",
        "        label = self.label\n",
        "        shape_data = data.shape\n",
        "        shape_label = label.shape\n",
        "        subject = shape_data[0]\n",
        "        trial = shape_data[1]\n",
        "        session = int(shape_data[1]/2)\n",
        "        channel = shape_data[4]\n",
        "        frequency = shape_data[5]\n",
        "        print(\"Train:Leave_one_session_out \\n1)shape of data:\" + str(shape_data) + \" \\n2)shape of label:\" + str(shape_label)+\n",
        "              \" \\n3)trials:\" + str(trial) + \" \\n4)sessions:\" + str(session) +\n",
        "              \" \\n5)datapoint:\" + str(frequency) + \" \\n6)channel:\" + str(channel))\n",
        "\n",
        "        ACC = []\n",
        "        ACC_mean = []\n",
        "        ACC_mean_val = []\n",
        "        for i in range(subject):\n",
        "            index = np.arange(trial)\n",
        "            ACC_subject = []\n",
        "            ACC_subject_val = []\n",
        "            for j in range(session):\n",
        "                index_train = np.delete(index, [2*j, 2*j+1])\n",
        "                index_test = index[2*j:2*(j+1)]\n",
        "\n",
        "                data_train = data[i, index_train, :, :, :, :].reshape(-1, channel * frequency)\n",
        "                label_train = label[i, index_train, :].reshape(-1)\n",
        "\n",
        "                data_test = data[i, index_test, :, :, :, :].reshape(-1, channel * frequency)\n",
        "                label_test = label[i, index_test, :].reshape(-1)\n",
        "\n",
        "                data_train, data_val, label_train, label_val = train_test_split(\n",
        "                    data_train, label_train, test_size=self.test_size, random_state=self.random_seed)\n",
        "\n",
        "                scaler = StandardScaler()\n",
        "                data_train = scaler.fit_transform(data_train)\n",
        "                data_val = scaler.transform(data_val)\n",
        "                data_test = scaler.transform(data_test)\n",
        "\n",
        "                # # Applying PCA\n",
        "                # pca = PCA(n_components=0.99)  # Keep 99% of variance\n",
        "                # data_train = pca.fit_transform(data_train)\n",
        "                # data_val = pca.transform(data_val)\n",
        "                # data_test = pca.transform(data_test)\n",
        "\n",
        "                model = SVC(kernel=self.kernel, C=self.C, gamma=self.gamma, random_state=self.random_seed, max_iter = 10000)\n",
        "                model.fit(data_train, label_train)\n",
        "\n",
        "                acc_train = fast_accuracy_score(label_train, model.predict(data_train))\n",
        "                acc_val = fast_accuracy_score(label_val, model.predict(data_val))\n",
        "                acc_test = fast_accuracy_score(label_test, model.predict(data_test))\n",
        "\n",
        "                ACC_subject.append(acc_test)\n",
        "                ACC_subject_val.append(acc_val)\n",
        "\n",
        "                print(f'Subject:{i}, Session:{j}, Train ACC:{acc_train:.4f}, Val ACC:{acc_val:.4f}, Test ACC:{acc_test:.4f}')\n",
        "\n",
        "            ACC_subject = np.array(ACC_subject)\n",
        "            mAcc = np.mean(ACC_subject)\n",
        "            std = np.std(ACC_subject)\n",
        "\n",
        "            ACC_val = np.array(ACC_subject_val)\n",
        "            mAcc_val = np.mean(ACC_val)\n",
        "\n",
        "            print(\"Subject:\" + str(i) + \"\\nmACC: %.2f\" % mAcc)\n",
        "            print(\"std: %.2f\" % std)\n",
        "\n",
        "            file = open(\"result_session.txt\", 'a')\n",
        "            file.write('Subject:' + str(i) + ' MeanACC:' + str(mAcc) + ' Std:' + str(std) + '\\n')\n",
        "            file.close()\n",
        "\n",
        "            ACC.append(ACC_subject)\n",
        "            ACC_mean.append(mAcc)\n",
        "            ACC_mean_val.append(mAcc_val)\n",
        "\n",
        "        self.result = ACC\n",
        "        file = open(\"result_session.txt\", 'a')\n",
        "        file.write(\"\\n\" + str(datetime.datetime.now()) + '\\nMeanACC:' + str(np.mean(ACC_mean)) +\n",
        "                   ' Std:' + str(np.std(ACC_mean)) + ' Mean Val ACC:' + str(np.mean(ACC_mean_val)) + '\\n')\n",
        "        file.close()\n",
        "        print(\"Mean ACC:\" + str(np.mean(ACC_mean)) + ' Std:' + str(np.std(ACC_mean)))\n",
        "\n",
        "        save_path = Path(os.getcwd())\n",
        "        filename_data = save_path / Path('Result_model/Result.hdf')\n",
        "        save_data = h5py.File(filename_data, 'w')\n",
        "        save_data['result'] = self.result\n",
        "        save_data.close()\n",
        "        return(np.mean(ACC_mean))\n",
        "\n",
        "print(f'Model with parameters: (kernel=\\'rbf\\', C=1.0, gamma=\\'scale\\') is starting...')\n",
        "train = TrainModel()\n",
        "train.load_data('data_split.hdf')\n",
        "train.set_parameter(cv='Leave_one_session_out', kernel='rbf', C=1.0, gamma='scale', test_size=0.2)\n",
        "train.Leave_one_session_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-hF1LNOVrZ4",
        "outputId": "13b8c0d4-6707-4269-dc2c-045e1f25fb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with parameters: (kernel='rbf', C=1.0, gamma='scale') is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:0.9940, Val ACC:0.5674, Test ACC:0.4111\n",
            "Subject:0, Session:1, Train ACC:0.9466, Val ACC:0.4978, Test ACC:0.4965\n",
            "Subject:0, Session:2, Train ACC:0.9542, Val ACC:0.5630, Test ACC:0.4634\n",
            "Subject:0\n",
            "mACC: 0.46\n",
            "std: 0.04\n",
            "Subject:1, Session:0, Train ACC:0.9826, Val ACC:0.8152, Test ACC:0.8197\n",
            "Subject:1, Session:1, Train ACC:0.9842, Val ACC:0.8283, Test ACC:0.8362\n",
            "Subject:1, Session:2, Train ACC:0.9798, Val ACC:0.8413, Test ACC:0.7857\n",
            "Subject:1\n",
            "mACC: 0.81\n",
            "std: 0.02\n",
            "Mean ACC:0.6354529616724739 Std:0.17842624854819983\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6354529616724739"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With PCA"
      ],
      "metadata": {
        "id": "oL5tTz1DEkRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def fast_accuracy_score(y_true, y_pred):\n",
        "    correct = 0\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] == y_pred[i]:\n",
        "            correct += 1\n",
        "    return correct / len(y_true)\n",
        "\n",
        "class TrainModel():\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.label = None\n",
        "        self.result = None\n",
        "        self.input_shape = None\n",
        "        self.cross_validation = 'Session' # Subject\n",
        "        self.sampling_rate = 256\n",
        "\n",
        "        # Parameters: Training process\n",
        "        self.random_seed = 42\n",
        "        self.num_class = 2\n",
        "        self.test_size = 0.2\n",
        "\n",
        "        # Parameters: Model\n",
        "        self.kernel = 'rbf'\n",
        "        self.C = 1.0\n",
        "        self.gamma = 'scale'\n",
        "\n",
        "    def load_data(self, path):\n",
        "        path = Path(path)\n",
        "        dataset = h5py.File(path, 'r')\n",
        "        self.data = np.array(dataset['data'])\n",
        "        self.label = np.array(dataset['label'])\n",
        "\n",
        "        # The input_shape should be (channel x data)\n",
        "        self.input_shape = self.data[0,0,0,0].shape\n",
        "\n",
        "        print('Data loaded!\\nData shape:[{}], Label shape:[{}]'\n",
        "              .format(self.data.shape,self.label.shape))\n",
        "\n",
        "    def set_parameter(self, cv, kernel, C, gamma, test_size):\n",
        "        self.kernel = kernel\n",
        "        self.C = C\n",
        "        self.gamma = gamma\n",
        "        self.test_size = test_size\n",
        "\n",
        "        # Save to log file for checking\n",
        "        if cv == \"Leave_one_subject_out\":\n",
        "            file = open(\"result_subject.txt\",'a')\n",
        "        elif cv == \"Leave_one_session_out\":\n",
        "            file = open(\"result_session.txt\",'a')\n",
        "        elif cv == \"K_fold\":\n",
        "            file = open(\"result_k_fold.txt\",'a')\n",
        "        file.write(\"\\n\"+ str(datetime.datetime.now())+\n",
        "              \"\\nTrain:Parameter setting for SVM\" +\n",
        "              \"\\n1)kernel:\" + str(self.kernel) + \"\\n2)C:\" + str(self.C) +\n",
        "              \"\\n3)gamma:\" + str(self.gamma) + \"\\n4)test_size:\" + str(self.test_size) + '\\n')\n",
        "\n",
        "        file.close()\n",
        "\n",
        "    def Leave_one_session_out(self):\n",
        "        save_path = Path(os.getcwd())\n",
        "        if not os.path.exists(save_path / Path('Result_model/Leave_one_session_out/history')):\n",
        "            os.makedirs(save_path / Path('Result_model/Leave_one_session_out/history'))\n",
        "\n",
        "        data = self.data\n",
        "        label = self.label\n",
        "        shape_data = data.shape\n",
        "        shape_label = label.shape\n",
        "        subject = shape_data[0]\n",
        "        trial = shape_data[1]\n",
        "        session = int(shape_data[1]/2)\n",
        "        channel = shape_data[4]\n",
        "        frequency = shape_data[5]\n",
        "        print(\"Train:Leave_one_session_out \\n1)shape of data:\" + str(shape_data) + \" \\n2)shape of label:\" + str(shape_label)+\n",
        "              \" \\n3)trials:\" + str(trial) + \" \\n4)sessions:\" + str(session) +\n",
        "              \" \\n5)datapoint:\" + str(frequency) + \" \\n6)channel:\" + str(channel))\n",
        "\n",
        "        ACC = []\n",
        "        ACC_mean = []\n",
        "        ACC_mean_val = []\n",
        "        for i in range(subject):\n",
        "            index = np.arange(trial)\n",
        "            ACC_subject = []\n",
        "            ACC_subject_val = []\n",
        "            for j in range(session):\n",
        "                index_train = np.delete(index, [2*j, 2*j+1])\n",
        "                index_test = index[2*j:2*(j+1)]\n",
        "\n",
        "                data_train = data[i, index_train, :, :, :, :].reshape(-1, channel * frequency)\n",
        "                label_train = label[i, index_train, :].reshape(-1)\n",
        "\n",
        "                data_test = data[i, index_test, :, :, :, :].reshape(-1, channel * frequency)\n",
        "                label_test = label[i, index_test, :].reshape(-1)\n",
        "\n",
        "                data_train, data_val, label_train, label_val = train_test_split(\n",
        "                    data_train, label_train, test_size=self.test_size, random_state=self.random_seed)\n",
        "\n",
        "                scaler = StandardScaler()\n",
        "                data_train = scaler.fit_transform(data_train)\n",
        "                data_val = scaler.transform(data_val)\n",
        "                data_test = scaler.transform(data_test)\n",
        "\n",
        "                # Applying PCA\n",
        "                pca = PCA(n_components=0.99)  # Keep 99% of variance\n",
        "                data_train = pca.fit_transform(data_train)\n",
        "                data_val = pca.transform(data_val)\n",
        "                data_test = pca.transform(data_test)\n",
        "\n",
        "                model = SVC(kernel=self.kernel, C=self.C, gamma=self.gamma, random_state=self.random_seed, max_iter = 100000)\n",
        "                model.fit(data_train, label_train)\n",
        "\n",
        "                acc_train = fast_accuracy_score(label_train, model.predict(data_train))\n",
        "                acc_val = fast_accuracy_score(label_val, model.predict(data_val))\n",
        "                acc_test = fast_accuracy_score(label_test, model.predict(data_test))\n",
        "\n",
        "                ACC_subject.append(acc_test)\n",
        "                ACC_subject_val.append(acc_val)\n",
        "\n",
        "                print(f'Subject:{i}, Session:{j}, Train ACC:{acc_train:.4f}, Val ACC:{acc_val:.4f}, Test ACC:{acc_test:.4f}')\n",
        "\n",
        "            ACC_subject = np.array(ACC_subject)\n",
        "            mAcc = np.mean(ACC_subject)\n",
        "            std = np.std(ACC_subject)\n",
        "\n",
        "            ACC_val = np.array(ACC_subject_val)\n",
        "            mAcc_val = np.mean(ACC_val)\n",
        "\n",
        "            print(\"Subject:\" + str(i) + \"\\nmACC: %.2f\" % mAcc)\n",
        "            print(\"std: %.2f\" % std)\n",
        "\n",
        "            file = open(\"result_session.txt\", 'a')\n",
        "            file.write('Subject:' + str(i) + ' MeanACC:' + str(mAcc) + ' Std:' + str(std) + '\\n')\n",
        "            file.close()\n",
        "\n",
        "            ACC.append(ACC_subject)\n",
        "            ACC_mean.append(mAcc)\n",
        "            ACC_mean_val.append(mAcc_val)\n",
        "\n",
        "        self.result = ACC\n",
        "        file = open(\"result_session.txt\", 'a')\n",
        "        file.write(\"\\n\" + str(datetime.datetime.now()) + '\\nMeanACC:' + str(np.mean(ACC_mean)) +\n",
        "                   ' Std:' + str(np.std(ACC_mean)) + ' Mean Val ACC:' + str(np.mean(ACC_mean_val)) + '\\n')\n",
        "        file.close()\n",
        "        print(\"Mean ACC:\" + str(np.mean(ACC_mean)) + ' Std:' + str(np.std(ACC_mean)))\n",
        "\n",
        "        save_path = Path(os.getcwd())\n",
        "        filename_data = save_path / Path('Result_model/Result.hdf')\n",
        "        save_data = h5py.File(filename_data, 'w')\n",
        "        save_data['result'] = self.result\n",
        "        save_data.close()\n",
        "        return(np.mean(ACC_mean))\n",
        "\n",
        "print(f'Model with parameters: (kernel=\\'rbf\\', C=1.0, gamma=\\'scale\\') is starting...')\n",
        "train = TrainModel()\n",
        "train.load_data('data_split.hdf')\n",
        "train.set_parameter(cv='Leave_one_session_out', kernel='rbf', C=1.0, gamma='scale', test_size=0.2)\n",
        "train.Leave_one_session_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIrxdJTQEm9X",
        "outputId": "d753dc3e-1cd1-481b-a51e-3d94d5445d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with parameters: (kernel='rbf', C=1.0, gamma='scale') is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:0.9924, Val ACC:0.5565, Test ACC:0.3885\n",
            "Subject:0, Session:1, Train ACC:0.9444, Val ACC:0.5065, Test ACC:0.4965\n",
            "Subject:0, Session:2, Train ACC:0.9526, Val ACC:0.5630, Test ACC:0.4617\n",
            "Subject:0\n",
            "mACC: 0.45\n",
            "std: 0.05\n",
            "Subject:1, Session:0, Train ACC:0.9826, Val ACC:0.8109, Test ACC:0.8319\n",
            "Subject:1, Session:1, Train ACC:0.9842, Val ACC:0.7913, Test ACC:0.8066\n",
            "Subject:1, Session:2, Train ACC:0.9793, Val ACC:0.8196, Test ACC:0.7439\n",
            "Subject:1\n",
            "mACC: 0.79\n",
            "std: 0.04\n",
            "Mean ACC:0.6215156794425087 Std:0.17261904761904767\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6215156794425087"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choosing best parameters for SVM"
      ],
      "metadata": {
        "id": "BBs2-7v7nKXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myACC = 0\n",
        "i = 1\n",
        "kernels = ['rbf', 'linear', 'poly']\n",
        "Cs = [1, 0.1, 10]\n",
        "gammas = ['scale', 'auto']\n",
        "for kernel in kernels:\n",
        "    for C in Cs:\n",
        "        for gamma in gammas:\n",
        "          print(' ')\n",
        "          print(f'Model number {i} with parameters: (kernel={kernel}, C={C}, gamma={gamma}) is starting...')\n",
        "          i = i + 1\n",
        "          train = TrainModel()\n",
        "          train.load_data('data_split.hdf')\n",
        "          train.set_parameter(cv='Leave_one_session_out', kernel=kernel, C=C, gamma=gamma, test_size=0.2)\n",
        "          newACC = train.Leave_one_session_out()\n",
        "          if newACC > myACC:\n",
        "            myACC = newACC\n",
        "            myKer = kernel\n",
        "            myC = C\n",
        "            myGamma = gamma\n",
        "print(' ')\n",
        "print(' ')\n",
        "print(f'Best ACC: {myACC}')\n",
        "print(f'Best Parameters: (kernel:{myKer}, C:{myC}, gamma:{myGamma})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Urt7UdjpTJA",
        "outputId": "9961da6f-ee08-45cd-b607-52d7884f19dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "Model number 1 with parameters: (kernel=rbf, C=1, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:0.9924, Val ACC:0.5565, Test ACC:0.3885\n",
            "Subject:0, Session:1, Train ACC:0.9444, Val ACC:0.5065, Test ACC:0.4965\n",
            "Subject:0, Session:2, Train ACC:0.9526, Val ACC:0.5630, Test ACC:0.4617\n",
            "Subject:0\n",
            "mACC: 0.45\n",
            "std: 0.05\n",
            "Subject:1, Session:0, Train ACC:0.9826, Val ACC:0.8109, Test ACC:0.8319\n",
            "Subject:1, Session:1, Train ACC:0.9842, Val ACC:0.7913, Test ACC:0.8066\n",
            "Subject:1, Session:2, Train ACC:0.9793, Val ACC:0.8196, Test ACC:0.7439\n",
            "Subject:1\n",
            "mACC: 0.79\n",
            "std: 0.04\n",
            "Mean ACC:0.6215156794425087 Std:0.17261904761904767\n",
            " \n",
            "Model number 2 with parameters: (kernel=rbf, C=1, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:1.0000, Val ACC:0.7152, Test ACC:0.4469\n",
            "Subject:0, Session:1, Train ACC:1.0000, Val ACC:0.6087, Test ACC:0.6220\n",
            "Subject:0, Session:2, Train ACC:1.0000, Val ACC:0.4739, Test ACC:0.5157\n",
            "Subject:0\n",
            "mACC: 0.53\n",
            "std: 0.07\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.5696, Test ACC:0.5488\n",
            "Subject:1, Session:1, Train ACC:1.0000, Val ACC:0.6370, Test ACC:0.6664\n",
            "Subject:1, Session:2, Train ACC:1.0000, Val ACC:0.5652, Test ACC:0.7038\n",
            "Subject:1\n",
            "mACC: 0.64\n",
            "std: 0.07\n",
            "Mean ACC:0.5839140534262486 Std:0.05574912891986067\n",
            " \n",
            "Model number 3 with parameters: (kernel=rbf, C=0.1, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:0.5076, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0, Session:1, Train ACC:0.5425, Val ACC:0.4826, Test ACC:0.5070\n",
            "Subject:0, Session:2, Train ACC:0.5948, Val ACC:0.5196, Test ACC:0.5061\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:0.7810, Val ACC:0.6739, Test ACC:0.7979\n",
            "Subject:1, Session:1, Train ACC:0.8105, Val ACC:0.7304, Test ACC:0.6672\n",
            "Subject:1, Session:2, Train ACC:0.7636, Val ACC:0.6957, Test ACC:0.8136\n",
            "Subject:1\n",
            "mACC: 0.76\n",
            "std: 0.07\n",
            "Mean ACC:0.6319686411149825 Std:0.12761324041811845\n",
            " \n",
            "Model number 4 with parameters: (kernel=rbf, C=0.1, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:0.5076, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0, Session:1, Train ACC:0.5076, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0, Session:2, Train ACC:0.5076, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:0.5076, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:1, Session:1, Train ACC:0.5076, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:1, Session:2, Train ACC:0.5076, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:1\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Mean ACC:0.5 Std:0.0\n",
            " \n",
            "Model number 5 with parameters: (kernel=rbf, C=10, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:1.0000, Val ACC:0.5826, Test ACC:0.3746\n",
            "Subject:0, Session:1, Train ACC:1.0000, Val ACC:0.5217, Test ACC:0.4538\n",
            "Subject:0, Session:2, Train ACC:1.0000, Val ACC:0.5630, Test ACC:0.4695\n",
            "Subject:0\n",
            "mACC: 0.43\n",
            "std: 0.04\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.8043, Test ACC:0.8249\n",
            "Subject:1, Session:1, Train ACC:1.0000, Val ACC:0.7935, Test ACC:0.8049\n",
            "Subject:1, Session:2, Train ACC:1.0000, Val ACC:0.8087, Test ACC:0.7605\n",
            "Subject:1\n",
            "mACC: 0.80\n",
            "std: 0.03\n",
            "Mean ACC:0.6146922183507549 Std:0.18205574912891992\n",
            " \n",
            "Model number 6 with parameters: (kernel=rbf, C=10, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:1.0000, Val ACC:0.6674, Test ACC:0.4094\n",
            "Subject:0, Session:1, Train ACC:1.0000, Val ACC:0.5478, Test ACC:0.5775\n",
            "Subject:0, Session:2, Train ACC:1.0000, Val ACC:0.4761, Test ACC:0.5131\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.07\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.6630, Test ACC:0.5784\n",
            "Subject:1, Session:1, Train ACC:1.0000, Val ACC:0.6826, Test ACC:0.7326\n",
            "Subject:1, Session:2, Train ACC:1.0000, Val ACC:0.6674, Test ACC:0.7875\n",
            "Subject:1\n",
            "mACC: 0.70\n",
            "std: 0.09\n",
            "Mean ACC:0.5997386759581882 Std:0.09973867595818815\n",
            " \n",
            "Model number 7 with parameters: (kernel=linear, C=1, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:0, Train ACC:0.7985, Val ACC:0.5326, Test ACC:0.4808\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:1, Train ACC:0.8061, Val ACC:0.5413, Test ACC:0.4747\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:2, Train ACC:0.6127, Val ACC:0.4457, Test ACC:0.5096\n",
            "Subject:0\n",
            "mACC: 0.49\n",
            "std: 0.02\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:0, Train ACC:0.5637, Val ACC:0.4543, Test ACC:0.5061\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:1, Train ACC:0.5458, Val ACC:0.4435, Test ACC:0.4739\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:2, Train ACC:0.5855, Val ACC:0.4870, Test ACC:0.4695\n",
            "Subject:1\n",
            "mACC: 0.48\n",
            "std: 0.02\n",
            "Mean ACC:0.4857723577235772 Std:0.0026132404181184177\n",
            " \n",
            "Model number 8 with parameters: (kernel=linear, C=1, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:0, Train ACC:0.7985, Val ACC:0.5326, Test ACC:0.4808\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:1, Train ACC:0.8061, Val ACC:0.5413, Test ACC:0.4747\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:2, Train ACC:0.6127, Val ACC:0.4457, Test ACC:0.5096\n",
            "Subject:0\n",
            "mACC: 0.49\n",
            "std: 0.02\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:0, Train ACC:0.5637, Val ACC:0.4543, Test ACC:0.5061\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:1, Train ACC:0.5458, Val ACC:0.4435, Test ACC:0.4739\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:2, Train ACC:0.5855, Val ACC:0.4870, Test ACC:0.4695\n",
            "Subject:1\n",
            "mACC: 0.48\n",
            "std: 0.02\n",
            "Mean ACC:0.4857723577235772 Std:0.0026132404181184177\n",
            " \n",
            "Model number 9 with parameters: (kernel=linear, C=0.1, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:0, Train ACC:0.9444, Val ACC:0.5609, Test ACC:0.4704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:1, Train ACC:0.9466, Val ACC:0.5435, Test ACC:0.4634\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:2, Train ACC:0.8824, Val ACC:0.4696, Test ACC:0.5052\n",
            "Subject:0\n",
            "mACC: 0.48\n",
            "std: 0.02\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:0, Train ACC:0.8148, Val ACC:0.4478, Test ACC:0.4878\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:1, Train ACC:0.7952, Val ACC:0.4043, Test ACC:0.4556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:2, Train ACC:0.8214, Val ACC:0.4717, Test ACC:0.4347\n",
            "Subject:1\n",
            "mACC: 0.46\n",
            "std: 0.02\n",
            "Mean ACC:0.4695121951219512 Std:0.010162601626016288\n",
            " \n",
            "Model number 10 with parameters: (kernel=linear, C=0.1, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:0, Train ACC:0.9444, Val ACC:0.5609, Test ACC:0.4704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:1, Train ACC:0.9466, Val ACC:0.5435, Test ACC:0.4634\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:2, Train ACC:0.8824, Val ACC:0.4696, Test ACC:0.5052\n",
            "Subject:0\n",
            "mACC: 0.48\n",
            "std: 0.02\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:0, Train ACC:0.8148, Val ACC:0.4478, Test ACC:0.4878\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:1, Train ACC:0.7952, Val ACC:0.4043, Test ACC:0.4556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:2, Train ACC:0.8214, Val ACC:0.4717, Test ACC:0.4347\n",
            "Subject:1\n",
            "mACC: 0.46\n",
            "std: 0.02\n",
            "Mean ACC:0.4695121951219512 Std:0.010162601626016288\n",
            " \n",
            "Model number 11 with parameters: (kernel=linear, C=10, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:0, Train ACC:0.7985, Val ACC:0.5326, Test ACC:0.4808\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:1, Train ACC:0.8061, Val ACC:0.5413, Test ACC:0.4747\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:2, Train ACC:0.6127, Val ACC:0.4457, Test ACC:0.5096\n",
            "Subject:0\n",
            "mACC: 0.49\n",
            "std: 0.02\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:0, Train ACC:0.5637, Val ACC:0.4543, Test ACC:0.5061\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:1, Train ACC:0.5458, Val ACC:0.4435, Test ACC:0.4739\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:1, Session:2, Train ACC:0.5855, Val ACC:0.4870, Test ACC:0.4695\n",
            "Subject:1\n",
            "mACC: 0.48\n",
            "std: 0.02\n",
            "Mean ACC:0.4857723577235772 Std:0.0026132404181184177\n",
            " \n",
            "Model number 12 with parameters: (kernel=linear, C=10, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject:0, Session:0, Train ACC:0.7985, Val ACC:0.5326, Test ACC:0.4808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject:0, Session:1, Train ACC:0.8061, Val ACC:0.5413, Test ACC:0.4747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject:0, Session:2, Train ACC:0.6127, Val ACC:0.4457, Test ACC:0.5096\n",
            "Subject:0\n",
            "mACC: 0.49\n",
            "std: 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject:1, Session:0, Train ACC:0.5637, Val ACC:0.4543, Test ACC:0.5061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject:1, Session:1, Train ACC:0.5458, Val ACC:0.4435, Test ACC:0.4739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject:1, Session:2, Train ACC:0.5855, Val ACC:0.4870, Test ACC:0.4695\n",
            "Subject:1\n",
            "mACC: 0.48\n",
            "std: 0.02\n",
            "Mean ACC:0.4857723577235772 Std:0.0026132404181184177\n",
            " \n",
            "Model number 13 with parameters: (kernel=poly, C=1, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:0.9858, Val ACC:0.4804, Test ACC:0.5035\n",
            "Subject:0, Session:1, Train ACC:0.8284, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0, Session:2, Train ACC:0.8856, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:1, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:2, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Mean ACC:0.5005807200929152 Std:0.0005807200929152101\n",
            " \n",
            "Model number 14 with parameters: (kernel=poly, C=1, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:0, Session:1, Train ACC:1.0000, Val ACC:0.5283, Test ACC:0.5000\n",
            "Subject:0, Session:2, Train ACC:1.0000, Val ACC:0.5348, Test ACC:0.5035\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:1, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:2, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Mean ACC:0.5005807200929152 Std:0.0005807200929152101\n",
            " \n",
            "Model number 15 with parameters: (kernel=poly, C=0.1, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:0.5240, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0, Session:1, Train ACC:0.5430, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0, Session:2, Train ACC:0.5588, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:0.5076, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:1, Session:1, Train ACC:0.5142, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:1, Session:2, Train ACC:0.5136, Val ACC:0.4696, Test ACC:0.5000\n",
            "Subject:1\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Mean ACC:0.5 Std:0.0\n",
            " \n",
            "Model number 16 with parameters: (kernel=poly, C=0.1, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:0, Session:1, Train ACC:1.0000, Val ACC:0.5283, Test ACC:0.5000\n",
            "Subject:0, Session:2, Train ACC:1.0000, Val ACC:0.5283, Test ACC:0.5000\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:1, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:2, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Mean ACC:0.5 Std:0.0\n",
            " \n",
            "Model number 17 with parameters: (kernel=poly, C=10, gamma=scale) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:0, Session:1, Train ACC:1.0000, Val ACC:0.5283, Test ACC:0.5000\n",
            "Subject:0, Session:2, Train ACC:1.0000, Val ACC:0.5283, Test ACC:0.5000\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:1, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:2, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Mean ACC:0.5 Std:0.0\n",
            " \n",
            "Model number 18 with parameters: (kernel=poly, C=10, gamma=auto) is starting...\n",
            "Data loaded!\n",
            "Data shape:[(2, 6, 574, 1, 4, 1024)], Label shape:[(2, 6, 574)]\n",
            "Train:Leave_one_session_out \n",
            "1)shape of data:(2, 6, 574, 1, 4, 1024) \n",
            "2)shape of label:(2, 6, 574) \n",
            "3)trials:6 \n",
            "4)sessions:3 \n",
            "5)datapoint:1024 \n",
            "6)channel:4\n",
            "Subject:0, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:0, Session:1, Train ACC:1.0000, Val ACC:0.5283, Test ACC:0.5000\n",
            "Subject:0, Session:2, Train ACC:1.0000, Val ACC:0.5348, Test ACC:0.5035\n",
            "Subject:0\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Subject:1, Session:0, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:1, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1, Session:2, Train ACC:1.0000, Val ACC:0.5304, Test ACC:0.5000\n",
            "Subject:1\n",
            "mACC: 0.50\n",
            "std: 0.00\n",
            "Mean ACC:0.5005807200929152 Std:0.0005807200929152101\n",
            " \n",
            " \n",
            "Best ACC: 0.6319686411149825\n",
            "Best Parameters: (kernel: rbf, C:0.1, gamma:scale)\n"
          ]
        }
      ]
    }
  ]
}