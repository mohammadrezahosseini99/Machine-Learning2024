# ML Course Projects Repository

This repository contains the implementations and analyses of various machine learning algorithms covered in the course. Each of the four projects delves into different facets of machine learning, including classification, regression, neural networks, and reinforcement learning.

## About Me

I am a student at K. N. Toosi University of Technology, specializing in Digital Electronics. This repository showcases my work throughout the Machine Learning course, where I have developed skills in implementing and evaluating various machine learning models using tools like Python and MATLAB. My experience spans supervised and unsupervised learning techniques, neural networks, and reinforcement learning algorithms. My passion for exploring cutting-edge technologies in machine learning drives me to continually expand my knowledge and apply it to real-world problems.

## Course Details

This machine learning course is part of the Digital Electronics program at K. N. Toosi University of Technology. It covers a wide range of machine learning topics, blending theoretical foundations with practical applications. Key areas of study include supervised and unsupervised learning, neural networks, and reinforcement learning. This course aims to equip students with the knowledge and skills to develop, implement, and evaluate machine learning models.

### Suggested Literature
- Tom Mitchell, “Machine Learning”, McGraw Hill, 1997.
- Christopher M. Bishop, “Pattern Recognition and Machine Learning”, Springer, 2006.
- S. Theodoridis and K. Koutroumbas, "Pattern Recognition", Academic Press, 2009.
- K. Murphy, “Machine Learning: A Probabilistic Perspective”, MIT Press, 2012.
- Martin T Hagan et al., “Neural Network Design”, 2nd Edition, 2014.

These texts provide a solid foundation in machine learning theories and practices, essential for understanding and implementing various algorithms.

### Key Topics Covered
1. **ML Fundamentals:** Introduction to machine learning principles, classifiers, and clustering. This includes an overview of different types of learning (supervised, unsupervised, and reinforcement learning) and foundational concepts.
2. **Regression Techniques:** Exploring least squares, gradient descent, and logistic regression. These techniques are vital for predictive modeling and understanding relationships between variables.
3. **Linear Models and Bayesian Methods:** Study of linear classifiers and Bayesian decision theory. These models are crucial for classification tasks and decision-making processes.
4. **Dimensionality Reduction Techniques:** Methods such as PCA and LDA to reduce feature space and improve model performance. Dimensionality reduction helps in visualizing data and removing noise.
5. **Support Vector Machines:** Analysis of linear and kernel-based SVMs for classification tasks. SVMs are powerful tools for high-dimensional data classification.
6. **Neural Networks:** Fundamentals and applications of neural networks, including MLP and backpropagation. Neural networks are essential for deep learning applications.
7. **Instance-Based Learning and Fuzzy Logic:** Techniques like KNN and fuzzy systems for flexible and adaptive learning. These methods are useful for scenarios where model interpretability is crucial.
8. **Decision Trees and Ensemble Methods:** Overview of decision trees, bagging, and boosting. Ensemble methods enhance predictive performance by combining multiple models.
9. **Reinforcement Learning:** Concepts including Q-learning and deep Q-networks. Reinforcement learning is key for developing intelligent agents that can make sequential decisions.
10. **Evolutionary Algorithms:** Exploring genetic algorithms and optimization methods. These algorithms are used for solving complex optimization problems.

## Project Descriptions

### Project 1: Classifier and Regression Model Implementation
- **Goal:** Train and assess classifiers and regression models using both synthetic and real-world datasets.
- **Key Elements:**
  - **Linear Classifier:** Training and evaluation on synthetic datasets. This involves understanding decision boundaries and classifier performance metrics.
  - **Multi-layer Perceptron (MLP):** Model training using the CWRU Bearing dataset. MLPs are evaluated on their ability to learn from feature-rich datasets.
  - **Regression Analysis:** Implementing LS, RLS, and WLS techniques. These regression models help in understanding the variability of data and making predictions.

### Project 2: Comparative Classifier Analysis
- **Goal:** Evaluate the performance of various classifiers on multiple datasets.
- **Key Elements:**
  - **MLP:** Implementation and performance evaluation with different architectures. This includes experimenting with hyperparameters and activation functions.
  - **Random Forest and Ensemble Methods:** Assessment of Random Forest and AdaBoost. Ensemble methods are compared based on their accuracy and robustness.
  - **Naive Bayes:** Application for probabilistic classification tasks. Naive Bayes classifiers are tested on their assumptions and performance under different conditions.

### Project 3: SVM and Dimensionality Reduction Impact
- **Goal:** Investigate the effect of dimensionality reduction on SVM performance.
- **Key Elements:**
  - **Dimensionality Reduction:** Techniques like t-SNE, PCA, and LDA. These techniques are evaluated on their ability to retain essential data features.
  - **SVM:** Evaluation with linear and polynomial kernels. SVMs are tested on their efficiency in different feature spaces.
  - **Data Preprocessing:** Using autoencoders for data denoising and SMOTE for class imbalance. These preprocessing steps are crucial for enhancing model performance.

### Project 4: Exploring Reinforcement Learning
- **Goal:** Implement reinforcement learning algorithms to solve the Wumpus World problem.
- **Key Elements:**
  - **Q-learning:** Training agents in a grid-based environment. Q-learning algorithms are evaluated on their learning efficiency and policy optimization.
  - **Deep Q-Networks (DQN):** Utilizing neural networks to approximate Q-values. DQNs are tested on their ability to generalize and handle large state spaces.
  - **Performance Evaluation:** Assessing agent performance based on reward metrics. Performance metrics help in understanding the effectiveness of reinforcement learning algorithms.

This repository reflects my journey through the Machine Learning course, demonstrating my ability to apply theoretical concepts to practical problems, and developing a deeper understanding of various machine learning techniques.